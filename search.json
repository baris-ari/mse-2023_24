[
  {
    "objectID": "index.html#welcome-to-mse-202324",
    "href": "index.html#welcome-to-mse-202324",
    "title": "Methods of Social Enquiry",
    "section": "Welcome to MSE (2023/24)",
    "text": "Welcome to MSE (2023/24)\nThis is the website of the Methods of Social Enquiry (PPLX7006).\nThe module has two in-person teaching components:\n\nThematic lectures (one-hour on Monday)\nApplied data analysis (two-hours on Thursday)\n\nAttendance is mandatory for all teaching sessions. If you cannot attend to any of the sessions, please make sure to submit an extenuating circumstances through eVision.\nWe will use this website for applied data analysis. The website is not a substitute for module Blackboard. We will use this site in conjunction with Blackboard."
  },
  {
    "objectID": "index.html#first-task-week-0",
    "href": "index.html#first-task-week-0",
    "title": "Methods of Social Enquiry",
    "section": "First Task (Week 0)",
    "text": "First Task (Week 0)\nOur very first task is to install R and R Studio on our laptops.\nPlease do this before coming to class on Thursday.\nR and R Studio are very powerful tools for analysing data and for creating high-quality documents. I prepared this website using R Studio. It is widely used both in academic research and in commercial enterprise. Learning the fundamentals of these powerful tools gives you an advantage in the job market (or for pursuing further studies such as PhD). They are free and open source.\nMake sure to install R first and then the R Studio.\n\nR can be installed here: https://cran.r-project.org/\nR Studio can be install here: https://posit.co/downloads/\n\nInstructions for installing R and R Studio are available in Appendix A of the Online Textbook Hands-on Programming with R."
  },
  {
    "objectID": "w01_rbasics.html#objectives-for-week-1",
    "href": "w01_rbasics.html#objectives-for-week-1",
    "title": "1  R Basics",
    "section": "1.1 Objectives for Week 1",
    "text": "1.1 Objectives for Week 1\n\nUse R as a calculator\nWrite and execute a command by using R Studio text editor\nSave your script\nUse the assignment operator to create objects\nUnderstand the difference between ‘string’ and ‘numerical’\nCreate a simple dataset"
  },
  {
    "objectID": "w01_rbasics.html#use-r-as-a-calculator",
    "href": "w01_rbasics.html#use-r-as-a-calculator",
    "title": "1  R Basics",
    "section": "1.2 Use R as a calculator",
    "text": "1.2 Use R as a calculator\nGo to the console pane and type a simple calculation.\n\n1 + 3\n#&gt; [1] 4\n\nAs you can see, the output for 1 + 3 is 4, which is correct. We directly did a calculation using the console.\nIt would work but it is not a good approach. Do not write your code directly to the console. Instead, go to the top left pane and write your ‘code’ into the text editor. The calculation 1 + 3 here is your code.\n\n\n\n\n\nFigure 1.2: Our first calculation\n\n\n\n\n\nSave your script by File &gt;&gt; Save OR simply by pressing ."
  },
  {
    "objectID": "w01_rbasics.html#assignment-operator-to-create-objects",
    "href": "w01_rbasics.html#assignment-operator-to-create-objects",
    "title": "1  R Basics",
    "section": "1.3 Assignment operator to create objects",
    "text": "1.3 Assignment operator to create objects\nWe can create objects in R which store our data. For example, you would like to calculate your age. Current year (i.e., 2023) - your birth year gives your age.\nLet’s create an object which stores your year of birth. We are going to call it my_birth_year. Each R object must be one-word only, so I use _ instead of space. We could also have used a dot or dash.\n\n# This is a comment. \n# Characters after a hashtag are considered as comments by R. \n# They are not executed.\n# Use comments extensively to take notes \n# and to remind your future self of the work you did. \n\n# \"&lt;-\" is the assignment operator\n# It basically symbolizes an arrow.\n\nmy_birth_year &lt;- 1985\n\nNow the Environment should store an object called my_birth_year. When I run my_birth_year, R will display the information stored.\n\nmy_birth_year\n#&gt; [1] 1985\n\nNote that R is case sensitive. If you mistype, such as My_birth_year, it will give you an error message.\n\nMy_birth_year\n#&gt; Error in eval(expr, envir, enclos): object 'My_birth_year' not found\n\nWe can find your age by subtracting current year from my_birth_year.\n\n2023 - my_birth_year\n#&gt; [1] 38\n\nWe typed 2023 manually. We might want to create another object called current_year. Try to do it yourself first as an exercise.\n\n\nReveal the code\ncurrent_year &lt;- 2023\n\n\nYou can do operations using objects. For example, calculate your age using the objects current_year and my_birth_year. Store this in another object called my_age.\n\n\nReveal the code\nmy_age &lt;- current_year - my_birth_year \n\n\nCheck if you did correctly.\n\nmy_age\n#&gt; [1] 38\n\nYou can also write over an object.\n\ncurrent_year &lt;- 2030\ncurrent_year\n#&gt; [1] 2030\n\nThis would not change outputs previously created using the older version of the objects.\n\nmy_age\n#&gt; [1] 38\n\nObviously, current yer is not 2030, so let’s correct it back.\n\ncurrent_year &lt;- 2023"
  },
  {
    "objectID": "w01_rbasics.html#numerical-and-string-objects",
    "href": "w01_rbasics.html#numerical-and-string-objects",
    "title": "1  R Basics",
    "section": "1.4 Numerical and String objects",
    "text": "1.4 Numerical and String objects\nSo far, we stored numerical data. We can also have textual information, such as name of a person, or type of a medicine.\nCreate an object called my_name and store your name there.\n\nmy_name &lt;- \"Baris\"\nmy_name\n#&gt; [1] \"Baris\"\n\nAs you can see, R displays textual information within quotation (’’). Any information stored or displayed within '' is called string and refers to text.\nCreate an object called my_name_last and store your name there.\n\n\nReveal the code\nmy_name_last &lt;- \"Ari\"\n\n\nObviously, you cannot make a calculation using words. It is nonsensical to subtract two words. You cannot do any calculation with words.\n\nmy_name_last - my_name\n#&gt; Error in my_name_last - my_name: non-numeric argument to binary operator\n\nSometimes numerical information is stored as text. In that case, R will not consider it as a number. For example, see three objects below.\n\nnum1 &lt;- 10\nnum2 &lt;- 100\nnum3 &lt;- \"1000\"\n\nnum1 and num2 are numerical values, but num3 is text. You cannot do any calculation with that.\n\nnum1\n#&gt; [1] 10\n\nnum2\n#&gt; [1] 100\n\nnum3\n#&gt; [1] \"1000\"\n\nnum1 + num2\n#&gt; [1] 110\n\nnum1 + num3\n#&gt; Error in num1 + num3: non-numeric argument to binary operator"
  },
  {
    "objectID": "w01_rbasics.html#create-a-simple-dataset",
    "href": "w01_rbasics.html#create-a-simple-dataset",
    "title": "1  R Basics",
    "section": "1.5 Create a Simple Dataset",
    "text": "1.5 Create a Simple Dataset\nImagine that we have the names and birth years of a number of people. We cannot really hold each piece of information in a separate object. We would like to store them altogether in a single object, like a spreadsheet.\nLet’s start with names. We have five people:\n\nRishi Sunak\nLiz Truss\nBoris Johnson\nTheresa May\nDavid Cameron\n\nWe can store their full names in a single object using the combine function c().\n\nnames_pm &lt;- c(\"Rishi Sunak\",\n              \"Liz Truss\",\n              \"Boris Johnson\",\n              \"Theresa May\",\n              \"David Cameron\",\n              \"Gordon Brown\",\n              \"Tony Blair\")\n\nNote that each PMs name is written within quotation and they are combined together with the function c(). Each item within c() is separated with a comma. Let’s see the object:\n\nnames_pm\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\nGreat! We have the names of the last five UK PMs.\nYou may have realized that there are numbers in squared brackets in the beginning of each line.\nThese numbers refer to the order in the sequence. For example, “Rishi Sunak” is the first item whereas “David Cameron” is the fifth.\nYou can recall a particular item in the object using square brackets. Let’s print the first item in names_pm.\n\nnames_pm[1]\n#&gt; [1] \"Rishi Sunak\"\n\nSimilarly, for the third item, you would use [3]:\n\nnames_pm[3]\n#&gt; [1] \"Boris Johnson\"\n\nFind the fifth name in the object.\n\n\nReveal the code\n\nnames_pm[5]\n#&gt; [1] \"David Cameron\"\n\n\nYou can add more than one number into the square brackets using the c() function. For example, who are the second and fourth names?\n\nnames_pm[c(2,4)]\n#&gt; [1] \"Liz Truss\"   \"Theresa May\"\n\nNext, let’s write down their birth year. The order is important! You need to keep the same order with PMs.\n\nbirth_years &lt;- c(1980, # Rishi Sunak\n                 1975, # Liz Truss\n                 1964, # Boris Johnson\n                 1956, # Theresa May\n                 1966, # David Cameron\n                 1951, # Gordon Brown\n                 1953  # Tony Blair)\n                 )\n\nCheck the object we just created.\n\nbirth_years\n#&gt; [1] 1980 1975 1964 1956 1966 1951 1953\n\nLet’s put them together in a spreadsheet. What we would like to do is to vertically bind the two objects, which is called column bind and denoted with cbind().\n\ncbind(names_pm, birth_years)\n#&gt;      names_pm        birth_years\n#&gt; [1,] \"Rishi Sunak\"   \"1980\"     \n#&gt; [2,] \"Liz Truss\"     \"1975\"     \n#&gt; [3,] \"Boris Johnson\" \"1964\"     \n#&gt; [4,] \"Theresa May\"   \"1956\"     \n#&gt; [5,] \"David Cameron\" \"1966\"     \n#&gt; [6,] \"Gordon Brown\"  \"1951\"     \n#&gt; [7,] \"Tony Blair\"    \"1953\"\n\nPut this into an object.\n\nmy_data &lt;- cbind(names_pm, birth_years)\n\nmy_data\n#&gt;      names_pm        birth_years\n#&gt; [1,] \"Rishi Sunak\"   \"1980\"     \n#&gt; [2,] \"Liz Truss\"     \"1975\"     \n#&gt; [3,] \"Boris Johnson\" \"1964\"     \n#&gt; [4,] \"Theresa May\"   \"1956\"     \n#&gt; [5,] \"David Cameron\" \"1966\"     \n#&gt; [6,] \"Gordon Brown\"  \"1951\"     \n#&gt; [7,] \"Tony Blair\"    \"1953\"\n\nNote that birth_years are stored as text, not numbers. I know this because they are within quotation marks.\nIt is customary to keep spreadsheets as something called “data frames” in R. This will not change our data, but makes further operations easier by unlocking some of the features of R.\n\nmy_data &lt;- as.data.frame(my_data)\n\nmy_data\n#&gt;        names_pm birth_years\n#&gt; 1   Rishi Sunak        1980\n#&gt; 2     Liz Truss        1975\n#&gt; 3 Boris Johnson        1964\n#&gt; 4   Theresa May        1956\n#&gt; 5 David Cameron        1966\n#&gt; 6  Gordon Brown        1951\n#&gt; 7    Tony Blair        1953\n\nWe can take a better look at the dataset using View() function.\n\n\nView(my_data)\n\nColumns in a data frame are also called variables. We have two variables in the dataset:\n\nnames_pm : Name of the UK PM\nbirth_years: Birth year of the PM\n\nThere are a few ways to access a variable. A straightforward approach is to use the $ notation:\n\n# 'name of the data frame'$'name of the variable' \nmy_data$names_pm\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\nNow it is your turn. Display the names variable.\n\n\nReveal the code\nmy_data$birth_years\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\n\nYou can think this expression as a sentence in R. In plain English, this expression tells R to bring the variable names_pm within the data frame my_data. The symbol $ refers to the ‘within’ part of this sentence.\nJust like you can convey the same meaning using different sentence structures, there are different ways to do the same thing in R. This is because R is working exactly like a language: it is a language to communicate with the computer.\nAnother way is using the square brackets notation []. names_pm is the first column in the data frame. To get the variable, you could type the following.\n\nmy_data[,1]\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\nNote that we did not simply write my_data[1]. There is a comma: my_data[,1]\nIn a spreadsheet, we have two dimensions: rows and columns. By convention, rows are considered as the first dimension, and columns are considered as the second. This is why we had to use a comma to designate that we are interested in columns. If left the first dimension unspecified, which tells R to bring everything.\nIf you want to get the first row, you would type the following.\n\nmy_data[1,]\n#&gt;      names_pm birth_years\n#&gt; 1 Rishi Sunak        1980\n\nTry it yourself; get the fourth row.\n\n\nReveal the code\nmy_data[4,]\n#&gt;      names_pm birth_years\n#&gt; 4 Theresa May        1956\n\n\nLet’s put these together: you can tell R to bring a specific observation. For example, third row of second column.\n\nmy_data[3,2]\n#&gt; [1] \"1964\"\n\nYou can also ask for multiple items by plugging in the combine function.\n\n# Third and fourth row of second column\nmy_data[c(3,4), 2]\n#&gt; [1] \"1964\" \"1956\""
  },
  {
    "objectID": "w02_data_types.html#class-of-an-object",
    "href": "w02_data_types.html#class-of-an-object",
    "title": "2  Data in R",
    "section": "2.1 Class of an object",
    "text": "2.1 Class of an object\nThe object birth_years is a numerical vector. It contains numbers. Let’s check the object.\n\nbirth_years\n#&gt; [1] 1980 1975 1964 1956 1966 1951 1953\n\nR understand the differences between textual and numerical information. We can check the class of an object using the class() function.\n\n# birth_years contain numerical information\nclass(birth_years)\n#&gt; [1] \"numeric\"\n\n# names_pm contain textual information, which is called character in R\nclass(names_pm)\n#&gt; [1] \"character\""
  },
  {
    "objectID": "w02_data_types.html#length-of-an-object",
    "href": "w02_data_types.html#length-of-an-object",
    "title": "2  Data in R",
    "section": "2.2 Length of an object",
    "text": "2.2 Length of an object\nWe typed names of last seven Prime Ministers and their respective birth years. The number of items in names_pm and birth_years should be both seven. We can see the number of items in a vector by the length() function.\n\n# Number of items in a vector can be seen by length()\n\n# Length of names_pm:\nlength(names_pm)\n#&gt; [1] 7\n\n# Length of birth_years:\nlength(birth_years)\n#&gt; [1] 7"
  },
  {
    "objectID": "w02_data_types.html#is-equal-to-operator",
    "href": "w02_data_types.html#is-equal-to-operator",
    "title": "2  Data in R",
    "section": "2.3 is equal to operator",
    "text": "2.3 is equal to operator\nYou can ask R whether two things are equal to each other or not. To do so, we are going to use the == operator, which means is equal to.\n\n# is equal to operator: ==\n# is the length of names_pm equal to birth_years\nlength(names_pm) == length(birth_years)\n#&gt; [1] TRUE\n# yes it is\n\n# is the class of names_pm equal to birth_years\nclass(names_pm) == class(birth_years)\n#&gt; [1] FALSE\n# no it is not\n# because names_pm contain textual information and birth_years contain numerical information"
  },
  {
    "objectID": "w02_data_types.html#creating-a-simple-dataset",
    "href": "w02_data_types.html#creating-a-simple-dataset",
    "title": "2  Data in R",
    "section": "2.4 Creating a simple dataset",
    "text": "2.4 Creating a simple dataset\nLast week we created a simple spreadsheet that looked like the data shown in Figure 2.1.\n\n\n\n\n\nFigure 2.1: A simple dataset\n\n\n\n\nWe can achieve this by doing a column bind which refers to vertically binding two vectors and can be done using the cbind() function.\n\nmy_data &lt;- cbind(names_pm, birth_years)\nmy_data\n#&gt;      names_pm        birth_years\n#&gt; [1,] \"Rishi Sunak\"   \"1980\"     \n#&gt; [2,] \"Liz Truss\"     \"1975\"     \n#&gt; [3,] \"Boris Johnson\" \"1964\"     \n#&gt; [4,] \"Theresa May\"   \"1956\"     \n#&gt; [5,] \"David Cameron\" \"1966\"     \n#&gt; [6,] \"Gordon Brown\"  \"1951\"     \n#&gt; [7,] \"Tony Blair\"    \"1953\"\n\nThe first column in my_data is names_pm and the second column is birth_years. We have now two dimensions: columns and rows.\nRecall that to ask R to bring a specific item in a two-dimensional object, such as a spreadsheet, we can use the square-brackets [] notation but we need to specify both dimension.\nFirst dimension refers to rows and second dimension refers to columns. For example, to get the third row in second column:\n\n# Third row in second column\nmy_data[3,2]\n#&gt; birth_years \n#&gt;      \"1964\"\n\nTo sum up, we bind two vectors by column. Each column is a vector. We can call these column vectors.\nTo get the first column, names_pm, we can use the square brackets notation.\n\n# Bring the first column\nmy_data[,1]\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\n# Bring the second column\nmy_data[,2]\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\nWe left the first dimension, which designates the row, unspecified to tell R to bring everything. We could also use column names instead of column numbers.\n\n# Bring the column birth_years\nmy_data[,\"birth_years\"]\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\n# Bring the column names_pm\nmy_data[,\"names_pm\"]\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\nWe can do the same for rows. To get a row vector, use the squared bracket notation.\n\n# Bring the first row\nmy_data[1, ]\n#&gt;      names_pm   birth_years \n#&gt; \"Rishi Sunak\"        \"1980\"\n\n# Bring the third row\nmy_data[3,]\n#&gt;        names_pm     birth_years \n#&gt; \"Boris Johnson\"          \"1964\"\n\n# Bring the fourth row\nmy_data[4,]\n#&gt;      names_pm   birth_years \n#&gt; \"Theresa May\"        \"1956\"\n\nR will give you an error message if you go out of bounds.\n\n# Bring the third column\nmy_data[,3]\n#&gt; Error in my_data[, 3]: subscript out of bounds\n\n# Bring the 10th row\nmy_data[10,]\n#&gt; Error in my_data[10, ]: subscript out of bounds\n\n# Bring the second column, ninth row\nmy_data[9,2]\n#&gt; Error in my_data[9, 2]: subscript out of bounds"
  },
  {
    "objectID": "w02_data_types.html#data-frame",
    "href": "w02_data_types.html#data-frame",
    "title": "2  Data in R",
    "section": "2.5 Data frame",
    "text": "2.5 Data frame\nIt is customary to keep a spreadsheet type of two-dimensional data as a data frame in R.\nLet’s check the class of my_data.\n\n# Class of my_data \nclass(my_data)\n#&gt; [1] \"matrix\" \"array\"\n\nIt looks like the class of my_data is “matrix” and “array”. Matrix is a two-dimensional array.\nWe can turn my_data into a data frame.\n\n# Turn my_data into data frame\nmy_data &lt;- as.data.frame(my_data)\n# this overwrote my_data as a data frame\n\n# Check its class\nclass(my_data)\n#&gt; [1] \"data.frame\"\n\nIn this module, we will primarily work with data frames.\nRecall that we can use the $ notation when working with data frames.\n\n# bring names_pm\nmy_data$names_pm\n#&gt; [1] \"Rishi Sunak\"   \"Liz Truss\"     \"Boris Johnson\" \"Theresa May\"  \n#&gt; [5] \"David Cameron\" \"Gordon Brown\"  \"Tony Blair\"\n\n# bring birth_years\nmy_data$birth_years\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\n# bring the third item in birth_years\nmy_data$birth_years[3]\n#&gt; [1] \"1964\"\n\nWe can check the number of columns and the number of rows of our data frame by using ncol() and nrow() functions.\n\n# number of columns\nncol(my_data)\n#&gt; [1] 2\n\n# number of rows\nnrow(my_data)\n#&gt; [1] 7\n\n# dimension:\ndim(my_data)\n#&gt; [1] 7 2\n# we have two dimensions: rows and columns, \n# first dimension has seven items.\n# second dimension has two items.\n\n# number of dimensions:\nlength(dim(my_data))\n#&gt; [1] 2\n\nNote that I put a function within a function when I put dim(my_data) into length().\n\n# number of dimensions:\nlength(dim(my_data))\n#&gt; [1] 2"
  },
  {
    "objectID": "w02_data_types.html#variable-row-observation",
    "href": "w02_data_types.html#variable-row-observation",
    "title": "2  Data in R",
    "section": "2.6 Variable, Row, Observation",
    "text": "2.6 Variable, Row, Observation\nSome more terminology that is frequently used in data analysis.\nA column vector typically shows a variable. A row vector typically shows an observation. A particularly item, which is a cell in a spreadsheet, is a value. This is visualised in Figure 2.2.\nWhen data do not come in this format, we will carry out something called data wrangling and reorganize the data so that each column is a variable, each row is an observation and each cell is a value. For simplicity, however, the datasets we are working on already come in this shape.\n\n\n\n\n\nFigure 2.2: Variables, observations, rows.\n\n\n\n\n\n# A variable: a column (e.g., birth_years)\nmy_data$birth_years\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\n# An observation: a row (e.g., second row)\nmy_data[2,]\n#&gt;    names_pm birth_years\n#&gt; 2 Liz Truss        1975\n\n# A particular value (e.g., third row of second column)\nmy_data[3,2]\n#&gt; [1] \"1964\""
  },
  {
    "objectID": "w02_data_types.html#numerical-value-stored-as-character",
    "href": "w02_data_types.html#numerical-value-stored-as-character",
    "title": "2  Data in R",
    "section": "2.7 Numerical value stored as character",
    "text": "2.7 Numerical value stored as character\nLet’s say we would like to calculate each person’s current age. We could simply tell R to subtract each birth year from current year (2023).\n\n2023 - my_data$birth_years\n#&gt; Error in 2023 - my_data$birth_years: non-numeric argument to binary operator\n\nInstead of the calculation, I get an error message: non-numeric argument to … Let’s see what is going on.\n\n# Check the variable of interest\nmy_data$birth_years\n#&gt; [1] \"1980\" \"1975\" \"1964\" \"1956\" \"1966\" \"1951\" \"1953\"\n\nbirth_years is a vector of numbers but if you look closely, you will see that each number is shown within a pair of quotation mark. This is because R is keeping each number as text at the moment. Let’s look at the class of the object.\n\n# Class of birth_years\nclass(my_data$birth_years)\n#&gt; [1] \"character\"\n\nCharacter means text. We are going to use as.numeric() function to tell R that information stored in birth_years is numerical, not text.\n\n# Convert the variable to numerical\nas.numeric(my_data$birth_years)\n#&gt; [1] 1980 1975 1964 1956 1966 1951 1953\n\n# Now quotation marks disappeared. \n# Beware: I have not overwritten the variable yet\nmy_data$birth_years &lt;- as.numeric(my_data$birth_years)\n\n# This command tells R to:\n# 1. go and get the variable birth_years inside the dataframe my_data\n# 2. convert it numeric\n# 3. take the numerical output and assign it over the variable birth_years\n\nNow birth_years should be numerical.\n\nclass(my_data$birth_years)\n#&gt; [1] \"numeric\"\n\nWe can create the current age variable.\n\n# Calculate the current age\n2023 - my_data$birth_years\n#&gt; [1] 43 48 59 67 57 72 70\n\n# It is working. Let's assign this output to a new variable\nmy_data$age_current &lt;- 2023 - my_data$birth_years\n\n# Check my_data\nmy_data\n#&gt;        names_pm birth_years age_current\n#&gt; 1   Rishi Sunak        1980          43\n#&gt; 2     Liz Truss        1975          48\n#&gt; 3 Boris Johnson        1964          59\n#&gt; 4   Theresa May        1956          67\n#&gt; 5 David Cameron        1966          57\n#&gt; 6  Gordon Brown        1951          72\n#&gt; 7    Tony Blair        1953          70"
  },
  {
    "objectID": "w02_data_types.html#categorical-data",
    "href": "w02_data_types.html#categorical-data",
    "title": "2  Data in R",
    "section": "2.8 Categorical data",
    "text": "2.8 Categorical data\nI would like to add a variable showing the party of each Prime Minister. I can create a vector and add this as a column in my_data.\nFor example, Rishi Sunak is from Conservative Party, Liz Truss is also Conservative. Indeed, only Gordon Brown and Tony Blair are Labour and the rest is Conservative.\nWe could write it one by one in order, but this would be cumbersome. We are going to use the replicate function.\n\n# Let's see the data\nmy_data\n#&gt;        names_pm birth_years age_current\n#&gt; 1   Rishi Sunak        1980          43\n#&gt; 2     Liz Truss        1975          48\n#&gt; 3 Boris Johnson        1964          59\n#&gt; 4   Theresa May        1956          67\n#&gt; 5 David Cameron        1966          57\n#&gt; 6  Gordon Brown        1951          72\n#&gt; 7    Tony Blair        1953          70\n\n# I need 5 \"Conservative\" followed by 2 \"Labour\"\n\n# You could write it one by one:\nc(\"Conservative\", \n  \"Conservative\", \n  \"Conservative\",\n  \"Conservative\",\n  \"Conservative\",\n  \"Labour\",\n  \"Labour\")\n#&gt; [1] \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\"\n#&gt; [6] \"Labour\"       \"Labour\"\n\n# But this is long and cumbersome. \n\n# Instead, let's use the replicate function. \n# I need 5 \"Conservative\" \nrep(\"Conservative\", 5)\n#&gt; [1] \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\"\n# and two Labour\nrep(\"Labour\", 2)\n#&gt; [1] \"Labour\" \"Labour\"\n\n# Let's put them together. Remember the order matters\nparty_vector &lt;- c(rep(\"Conservative\", 5),\n                  rep(\"Labour\", 2)\n                  )\n\nparty_vector\n#&gt; [1] \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\" \"Conservative\"\n#&gt; [6] \"Labour\"       \"Labour\"\n\nI created an object called party. Let’s add this as a variable in my_data.\n\n# Let's check that number of items in party is equal to number of rows in my_data\nnrow(my_data) == length(party_vector)\n#&gt; [1] TRUE\n\n# assign the party variable\nmy_data$party &lt;- party_vector\n\n# check the dataframe\nmy_data\n#&gt;        names_pm birth_years age_current        party\n#&gt; 1   Rishi Sunak        1980          43 Conservative\n#&gt; 2     Liz Truss        1975          48 Conservative\n#&gt; 3 Boris Johnson        1964          59 Conservative\n#&gt; 4   Theresa May        1956          67 Conservative\n#&gt; 5 David Cameron        1966          57 Conservative\n#&gt; 6  Gordon Brown        1951          72       Labour\n#&gt; 7    Tony Blair        1953          70       Labour\n\nWe can use table() to see how many PMs from each party.\n\ntable(my_data$party)\n#&gt; \n#&gt; Conservative       Labour \n#&gt;            5            2"
  },
  {
    "objectID": "w02_data_types.html#saving-data",
    "href": "w02_data_types.html#saving-data",
    "title": "2  Data in R",
    "section": "2.9 Saving data",
    "text": "2.9 Saving data\nIn the final step, we will learn how to save a dataframe such as my_data for future use. We have a few options:\n\nWrite my_data into a spreadsheet-like file.\nSave the whole R environment with all the objects inside.\n\nWe will cover option #1 here.\nYou have probably used Microsoft Excel (or Google Sheets) to work on spreadsheets before. There are different spreadsheet file types (such as Excels .xlsx), but the most common and compatible one is .csv, which stands for comma separated values. This is basically plain text that any computer and most electronic devices can open.\n\nwrite.csv(x = my_data, file = \"my_first_file.csv\", row.names = F)\n\nThis should create a file somewhere in your computer, more precisely, in your working directory. Let’s see where it has saved the file by looking at the working directory.\n\ngetwd()"
  },
  {
    "objectID": "w02_data_types.html#working-directory",
    "href": "w02_data_types.html#working-directory",
    "title": "2  Data in R",
    "section": "2.10 Working directory",
    "text": "2.10 Working directory\ngetwd() means get working directory. Working directory is your default file path. This is where R looks for files and saves any output.\nWorking directory can be different in each computer. R Studio has nice tools for navigation.\nYou can directly go to your working directory through Files tab (usually in right bottom corner) and More drop-down menu. Under there there are a few options:\n\nSet as working directory: sets your working directory as the current directory shown in Files\nGo to working directory: takes you to current working directory\n\nIf you click on go to working directory, you should see my_first_file.csv here.\nIt is a good idea to create a new directory (folder for Windows) for this module. Your folder names should be simple and easy to write. For example: mse_23-24 is a good name. Try not to use space in file names. Underscore and dash are better alternatives. Also, I encourage always using lowercase for file names, which also goes for object names in R.\nYou can use your operating system to create this directory. You could also use R Studio’s Files tab. Put this folder somewhere easy to access.\nLet’s save your R script. You can use drop-down menu: File &gt;&gt; Save OR simply by using the keyboard shortcut .\nGive an intuitive name to your script. For example, 01_RBasics.R is a good name.\nIt is generally good idea to keep your data in a sub-directory named data. Create such a directory and move my_first_file.csv there.\nNext week, we will continue with a simple dataset, which will be available on Blackboard."
  },
  {
    "objectID": "w03_data_analysis.html#load-a-.csv-file",
    "href": "w03_data_analysis.html#load-a-.csv-file",
    "title": "3  Basic Data Analysis",
    "section": "3.1 Load a .csv file",
    "text": "3.1 Load a .csv file\nFor practice purposes, let’s load the simple dataframe we created last week. We will use read.csv() function. Recall that the file is under the folder data.\n\nread.csv(\"data/my_first_file.csv\")\n#&gt;        names_pm birth_years age_current        party\n#&gt; 1   Rishi Sunak        1980          43 Conservative\n#&gt; 2     Liz Truss        1975          48 Conservative\n#&gt; 3 Boris Johnson        1964          59 Conservative\n#&gt; 4   Theresa May        1956          67 Conservative\n#&gt; 5 David Cameron        1966          57 Conservative\n#&gt; 6  Gordon Brown        1951          72       Labour\n#&gt; 7    Tony Blair        1953          70       Labour\n\nLet’s download data World in 2010. This dataset is available on Blackboard. It can also be downloaded from here. A codebook is also available on Blackboard. Make sure to take a look at it.\nLet’s be tidy and move this file into the data folder under our module folder. You can navigate in your module directory within R Studio. For example, in Figure 3.2 files tab show the folder data.\n\n\n\n\n\nFigure 3.2: Files tab in R Studio\n\n\n\n\nYou can actually list files in your computer with R commands too!\n\n# list files under working directory\nlist.files()\n\n\n# list files under data folder \nlist.files(\"data/\")\n#&gt; [1] \"my_first_file.csv\" \"putnam.csv\"        \"world_in_2010.csv\"\n\nNow we are ready to load world_in_2010.csv into R. We should also have a sense of the dataset.\n\n# load data:\ndf &lt;- read.csv(\"data/world_in_2010.csv\")\n\n# have a look\nView(df)\n\n# type of the object\nclass(df)\n#&gt; [1] \"data.frame\"\n\n# how many variables?\nncol(df)\n#&gt; [1] 42\n\n# how many rows?\nnrow(df)\n#&gt; [1] 166\n\n# names of the variables\nnames(df)\n#&gt;  [1] \"COWcode\"                             \"Country_Code\"                       \n#&gt;  [3] \"Country_Name\"                        \"WB_Region\"                          \n#&gt;  [5] \"WB_IncomeGroup\"                      \"Population_total\"                   \n#&gt;  [7] \"Urban_pop\"                           \"GDP_pc_PPP\"                         \n#&gt;  [9] \"Infant_Mortality_Rate\"               \"Life_exp_female\"                    \n#&gt; [11] \"Life_exp_male\"                       \"HIV\"                                \n#&gt; [13] \"Literacy_rate_female\"                \"Literacy_rate_all\"                  \n#&gt; [15] \"Current_acc_bal_USD\"                 \"Current_acc_bal_perc_of_GDP\"        \n#&gt; [17] \"ODA_USD\"                             \"ODA_perc_of_GNI\"                    \n#&gt; [19] \"Natural_resources_rents_perc_of_GDP\" \"FDI_net_inflows_perc_of_GDP\"        \n#&gt; [21] \"Net_migration_2008_2012\"             \"GINI_index_WB_estimate\"             \n#&gt; [23] \"Inc_share_by_highest_10per\"          \"Unemployment_rate\"                  \n#&gt; [25] \"Surface_area_sq_km\"                  \"v2x_polyarchy\"                      \n#&gt; [27] \"democracy\"                           \"v2x_libdem\"                         \n#&gt; [29] \"v2x_egaldem\"                         \"Geographical_Region\"                \n#&gt; [31] \"UN_vote_PctAgreeUS\"                  \"UN_vote_PctAgreeRUSSIA\"             \n#&gt; [33] \"UN_vote_PctAgreeBrazil\"              \"UN_vote_PctAgreeChina\"              \n#&gt; [35] \"UN_vote_PctAgreeIndia\"               \"UN_vote_PctAgreeIsrael\"             \n#&gt; [37] \"milex\"                               \"milper\"                             \n#&gt; [39] \"cinc\"                                \"CivilConflict\"                      \n#&gt; [41] \"Corruptions_Perspectives_Index\"      \"Turnout\"\n\nEach row represents a state in the international system. So we can say that the unit of observation is the state. Variables show several attributes of each state (note that I will use state and country interchangeable).\nWe call this a cross-sectional data because we have units but no time dimension. The whole dataset is for the year 2010. Usually, such country-level data would also contain multiple years so that comparison can be over-time, but to keep things simple for now, we are only working with a single year. When we add the time dimension to cross-sectional data, we will call it time-series cross-sectional.\nHow many countries do we have in this dataset? We already know the answer because we checked the number of rows. Recall that each row represents a state in the international system so that the total number of rows will give me the number of countries in the data.\n\n# how many rows?\nnrow(df)\n#&gt; [1] 166"
  },
  {
    "objectID": "w03_data_analysis.html#summary-of-a-categorical-variable",
    "href": "w03_data_analysis.html#summary-of-a-categorical-variable",
    "title": "3  Basic Data Analysis",
    "section": "3.2 Summary of a Categorical Variable",
    "text": "3.2 Summary of a Categorical Variable\nLet’s describe a categorical variable. We can work with Geographical_Region, which records where a country is located geographically. To see how many countries are in each region, we can use table() and provide a descriptive summary of this variable.\n\ntable(df$Geographical_Region)\n#&gt; \n#&gt;                   Africa                 Americas                     Asia \n#&gt;                       47                       27                       30 \n#&gt;                   Europe Mid. East & North Africa                   Ocenia \n#&gt;                       39                       17                        6\n\nNow, we have a frequency table of Geographical_Region. I can see that 47 countriese are in Africa, 27 in Americas and so on. For categorical variables, a frequency table is appropriate for a descriptive summary.\nWe can also create a bar plot and visually summarize the data. Each bar will represent the number of countries in each geographical region. In short, we will visually display the information in table(df$Geographical_Region) using a barplot.\n\nbarplot(height = table(df$Geographical_Region))\n\n\n\n\nThis is a good start, but we will do better. Before going any further, let’s unpack the code. The function barplot() takes a vector of numbers, which it uses to display heights. For instance, if we want to display four bars with heights 5, 10, 12 and 7, we can plug such a vector into barplot().\n\nbarplot(height = c(5,10,12,7))\n\n\n\n\nNote that bars above don’t have labels at the moment, because we did not provide any information. For Geographical_Region, however, table() creates a named vector.\n\n# A named vector:\ntable(df$Geographical_Region)\n#&gt; \n#&gt;                   Africa                 Americas                     Asia \n#&gt;                       47                       27                       30 \n#&gt;                   Europe Mid. East & North Africa                   Ocenia \n#&gt;                       39                       17                        6\n\n# Names:\nnames(table(df$Geographical_Region))\n#&gt; [1] \"Africa\"                   \"Americas\"                \n#&gt; [3] \"Asia\"                     \"Europe\"                  \n#&gt; [5] \"Mid. East & North Africa\" \"Ocenia\"\n\nGoing back to our hypothetical barplot, we can provide it a names argument. Let’s say the numbers 5, 10, 12 and 7 correspond to Orange, Banana, Apple, Pear.\n\nbarplot(height = c(5,10,12,7), names.arg = c(\"Orange\", \"Banana\", \"Apple\", \"Pear\"))\n\n\n\n\nSo the barplot() above took the height and names.arg arguments.\nFor easier read and navigation, it is a good idea to use a systematic way to write the code. You can press ↵ after the end of the first argument.\n\n# easier to read code\nbarplot(height = c(5,10,12,7), \n        names.arg = c(\"Orange\", \"Banana\", \"Apple\", \"Pear\")\n        )\n\n\n\n\nNow we have a very good idea how barplot() works. Going back to the bar plot for Geographical_Region, the category “Mid. East & North Africa” is too long. I want to change it with just “MENA”.\nYou can take assign table input to an object and work on it.\n\n# Get the table() into an object\nbarplot_input &lt;- table(df$Geographical_Region)\n\n# Check the object\nbarplot_input\n#&gt; \n#&gt;                   Africa                 Americas                     Asia \n#&gt;                       47                       27                       30 \n#&gt;                   Europe Mid. East & North Africa                   Ocenia \n#&gt;                       39                       17                        6\n\n# check the names of each value\nnames(barplot_input)\n#&gt; [1] \"Africa\"                   \"Americas\"                \n#&gt; [3] \"Asia\"                     \"Europe\"                  \n#&gt; [5] \"Mid. East & North Africa\" \"Ocenia\"\n\nFifth item in names(barplot_input) is “Mid. East & North Africa”. I could go and change it by using the squared bracket [] notation.\n\n# Fifth Item in Barplot\nnames(barplot_input)[5]\n#&gt; [1] \"Mid. East & North Africa\"\n\n# To change it you can assign a new name\nnames(barplot_input)[5] &lt;- \"MENA\"\n\n# Check the object again\nbarplot_input\n#&gt;   Africa Americas     Asia   Europe     MENA   Ocenia \n#&gt;       47       27       30       39       17        6\n\nNow we can do the barplot.\n\nbarplot(barplot_input)\n\n\n\n\nWe changed the name successfully."
  },
  {
    "objectID": "w03_data_analysis.html#caution-hard-coding-can-create-problems",
    "href": "w03_data_analysis.html#caution-hard-coding-can-create-problems",
    "title": "3  Basic Data Analysis",
    "section": "3.3 Caution! Hard-coding can create problems",
    "text": "3.3 Caution! Hard-coding can create problems\nIt is important highlight that we are doing this exercise for learning purposes. We are trying to understand how we can deal with data, manipulate variables, change names, etc.\nWe used the following code as a shortcut for learning purposes:\n\nnames(barplot_input)[5] &lt;- \"MENA\"\n\nThis code tells R to the following:\n\ntake the names() of barplot_input\ngo to the fifth item\nchange it with “MENA”\n\nThis is problematic because we are specifying fifth item in a way that if the data (or the order of categories) change for any reason (e.g., a new update), you\nThis is called hard-coding and should be avoided as much as possible.\nInstead we want to tell the following:\n\ntake the names() of barplot_input\ngo to “Mid. East & North Africa”\nchange it with “MENA”\n\nLet’s start again and re-create barplot_input.\n\n# barplot_input: table of df$Geographical_Region\nbarplot_input &lt;- table(df$Geographical_Region)\n\n# names are back to original \nbarplot_input\n#&gt; \n#&gt;                   Africa                 Americas                     Asia \n#&gt;                       47                       27                       30 \n#&gt;                   Europe Mid. East & North Africa                   Ocenia \n#&gt;                       39                       17                        6\n\n# Hard-coding (should be avoided): get me the fifth item\nnames(barplot_input)[5]\n#&gt; [1] \"Mid. East & North Africa\"\n\n# Instead of a hard-coded item number such as 5\n# We are going to write a statement inside:\n# get me \"Mid. East & North Africa\"\nnames(barplot_input)[names(barplot_input) == \"Mid. East & North Africa\"]\n#&gt; [1] \"Mid. East & North Africa\"\n\nSo, we put the statement names(barplot_input) == \"Mid. East & North Africa\" instead of hard-coding the item number, five. Recall that == stands for is equal to. This statement itself gives me a logical vector.\n\nnames(barplot_input) == \"Mid. East & North Africa\"\n#&gt; [1] FALSE FALSE FALSE FALSE  TRUE FALSE\n\nYou should see that the fifth item is TRUE and the others are FALSE. Instead of writing 5 by keyboard, we futureproof ourselves by putting in a statement.\n\nGo to vector names(barplot_input)\nFind the value where names(barplot_input) is equal to “Mid. East & North Africa”\n\nChange it to “MENA”\n\n\nnames(barplot_input)[names(barplot_input) == \"Mid. East & North Africa\"] &lt;- \"MENA\"\n\nWe have the barplot below.\n\nbarplot(barplot_input)\n\n\n\n\nWe can make this graph prettier by adding titles and ordering by region.\n\n# sort by frequency\nbarplot_input &lt;- sort(barplot_input, decreasing = T)\n\n# barplot:\nbarplot(barplot_input, \n        main = \"Number of Countries by Region\",\n        ylab = \"Number of Countries\"\n        )\n\n\n\n\nCheck the help file for barplot() to see all the arguments you can plug in.\n\n?barplot()"
  },
  {
    "objectID": "w03_data_analysis.html#summary-of-a-numerical-variable",
    "href": "w03_data_analysis.html#summary-of-a-numerical-variable",
    "title": "3  Basic Data Analysis",
    "section": "3.4 Summary of a Numerical Variable",
    "text": "3.4 Summary of a Numerical Variable\nNext, let’s work with a numerical variable. Life_exp_female is a measurement of female life expectancy across the world in 2010. The function summary() will give the min, max, mean, median, and first and third quartiles.\n\n# Summary of the variable\nsummary(df$Life_exp_female)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   48.88   64.41   74.91   71.94   78.73   86.30\n\nWe can also check such statistics one by one.\n\n# mean of a variable\nmean(df$Life_exp_female)\n#&gt; [1] 71.94012\n\n# minimum\nmin(df$Life_exp_female)\n#&gt; [1] 48.88\n\n# maximum\nmax(df$Life_exp_female)\n#&gt; [1] 86.3\n\nRecall that quartiles divides the data into four parts. Median is the mid-point, which is also called the second quartile.\n\nFive-point Summary\n\n\n\n\n\n\n\n\nSymbol\nName(s)\nDefinition\nUse\n\n\n\n\nMin\nMinimum\nMinimum of data\nChecking the minimum boundary\n\n\nQ1\nFirst Quartile\n25th Percentile\nsplits off\nthe lowest 25% of data\nfrom the highest 75%\nTypical low value\n\n\nQ2\nMedian\nSecond Quartile\n50th Percentile\nmiddle of data\ncuts data set in half\nMid-point\nTypical value\n\n\nQ3\nThird Quartile\n75th Percentile\nsplits off\nthe highest 25% of data\nfrom the lowest 75%\nTypical high value\n\n\nMax\nMaximum\nMaximum of data\nChecking the maximum boundary\n\n\n\nBesides summary() we can also use median() and quantile() functions to get the quartiles.\n\n# median:\nmedian(df$Life_exp_female)\n#&gt; [1] 74.905\n\n# also median:\nquantile(df$Life_exp_female, probs = 0.50) # 0.50 indicates half-way (50%)\n#&gt;    50% \n#&gt; 74.905\n\n# first quartile\nquantile(df$Life_exp_female, probs = 0.25) # 0.25 indicates 25%\n#&gt;   25% \n#&gt; 64.41\n\n# third quartile\nquantile(df$Life_exp_female, probs = 0.75) # 0.75 indicates 75%\n#&gt;   75% \n#&gt; 78.73\n\n# five point summary\nquantile(df$Life_exp_female, probs = c(0, 0.25, 0.50, 0.75, 1))\n#&gt;     0%    25%    50%    75%   100% \n#&gt; 48.880 64.410 74.905 78.730 86.300\n\nUsing summary() to get a five-point numerical summary is perfectly fine. We briefly visited quantile() for demonstration purposes. There are many ways to achieve the same thing in R.\nFor dispersion, variance and standard deviation can be calculated.\n\n# standard deviation\nsd(df$Life_exp_female)\n#&gt; [1] 9.353926\n\n# variance\nvar(df$Life_exp_female)\n#&gt; [1] 87.49594\n\n# recall that square root of variance is standard deviation\nsqrt( var(df$Life_exp_female) )\n#&gt; [1] 9.353926\n\n# ask R if you don't believe me\nsd(df$Life_exp_female) == sqrt( var(df$Life_exp_female) )\n#&gt; [1] TRUE"
  },
  {
    "objectID": "w03_data_analysis.html#visual-summary",
    "href": "w03_data_analysis.html#visual-summary",
    "title": "3  Basic Data Analysis",
    "section": "3.5 Visual Summary",
    "text": "3.5 Visual Summary\nWhen working on a new dataset, it is always a good idea to start by visually summarizing your variables one by one. This will help you to get a sense of the data.\nFor a numerical variable, two types of graphs are appropriate for a visual summary:\n\nHistogram\nBox plot\n\n\n3.5.1 Histogram\n\n# histogram:\nhist(df$Life_exp_female)\n\n\n\n\nYou can tell R how many bins you would like to have in your histogram by using the breaks argument, but as the R help file clarifies, this number is a suggestion only, and R can use a different (but similar value) to draw a pretty histogram.\n\n# histogram with fewer bins\nhist(df$Life_exp_female, breaks = 5)\n\n\n\n\n# histogram with higher number of bins\nhist(df$Life_exp_female, breaks = 30)\n\n\n\n\nYou might want to specify cut points. For example, you might want to have a sequence from 40 to 100 with increment of 5.\n\n# a sequence from 40 to 100 by 5\nseq(from = 40, to = 100, by = 5)\n#&gt;  [1]  40  45  50  55  60  65  70  75  80  85  90  95 100\n\n# put it into an object\nmy_breaks &lt;- seq(from = 40, to = 100, by = 5)\n\n# this will be our break points\n\n#tell R to do the histogram using these points\nhist(df$Life_exp_female, breaks = my_breaks)\n\n\n\n\nThis looks quite nice and intuitive. However, titles are not defined. I don’t want to see df$Life_exp_female as an axis or main graph title.\n\n#Histogram with titles and breaks\nhist(df$Life_exp_female, \n     breaks = my_breaks, \n     main = \"Female Life Expectancy in 2010\",\n     ylab = \"Number of Countries\",\n     xlab = \"Age\"\n     )\n\n\n\n\n\n\n3.5.2 Boxplot\nAnother graphical summary for a numerical variable is box plot. They are really nice to get a sense of the data, understand the distribution, and quickly see if there are any outliers. They are also very good at creating visual comparisons across groups, something which we will cover in upcoming weeks.\n\n# Boxplot\nboxplot(df$Life_exp_female,\n        main = \"Female Life Expectancy in 2010\",\n        ylab = \"Age\")\n\n\n\n\nThis box plot helps us to visualize the five-point summary. You can see minimum, max, median and first and third quartiles.\nIf you don’t believe me, we can plot these over the boxplot.\n\n# box plot:\nboxplot(df$Life_exp_female,\n        main = \"Female Life Expectancy in 2010\",\n        ylab = \"Age\")\n\n# you can add a line to a plot by abline\n# h stands for horizontal\n# tell R to draw a horizontal line at the median of Life_exp_female\nabline(h = median(df$Life_exp_female))\n\n\n\n\nYou can draw lines for each statistic.\n\n# box plot:\nboxplot(df$Life_exp_female,\n        main = \"Female Life Expectancy in 2010\",\n        ylab = \"Age\")\n\n# median\nabline(h = median(df$Life_exp_female))\n\n# min\nabline(h = min(df$Life_exp_female))\n\n# max\nabline(h = max(df$Life_exp_female))\n\n# first quartile\nabline(h = quantile(df$Life_exp_female, probs = 0.25))\n\n# third quartile\nabline(h = quantile(df$Life_exp_female, probs = 0.75))\n\n\n\n\nWe drew these lines for demonstration purposes and show that a box plot visualizes the information in a five-point summary."
  },
  {
    "objectID": "w03_data_analysis.html#dealing-with-missingness",
    "href": "w03_data_analysis.html#dealing-with-missingness",
    "title": "3  Basic Data Analysis",
    "section": "3.6 Dealing with missingness",
    "text": "3.6 Dealing with missingness\nSometimes our variable of interest may have missing values inside. For example, GDP per capita PPP (PPP stands for purchasing power parity) variable is GDP_pc_PPP. GDP data for some countries are missing.\n\nsummary(df$GDP_pc_PPP)\n#&gt;     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n#&gt;    646.9   3127.0   9627.9  15494.4  20497.9 122609.4        5\n\nNA’s here means missing. GDP data for five countries are not available. Let’s find these five countries. The function is.na() tells whether something is missing or not.\n\n# is GDP_pc_PPP missing\nis.na(df$GDP_pc_PPP)\n#&gt;   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n#&gt;  [37] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt;  [97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt; [109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt; [121]  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt; [133] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n#&gt; [145] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n#&gt; [157] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n\n# what is the name of the country with missing GDP_pc_PPP\ndf$Country_Name[is.na(df$GDP_pc_PPP) == TRUE]\n#&gt; [1] \"Cuba\"       \"Djibouti\"   \"Korea, Dem\" \"Somalia\"    \"Syrian Ara\"\n\n# you can think the statement above as this:\n# Bring 'Country Name' such that 'GDP' is missing\n\nDealing with missingness appropriately is important because it might create problems. For example, regular functions mean() and max() will get confused if we do not deal with missingness explicitly.\n\n# mean of GDP_pc_PPP\nmean(df$GDP_pc_PPP)\n#&gt; [1] NA\n\n# R tells me it is missing \n# because you cannot make a calculation with a missing value\n\n# Tell R that to remove missing values\nmean(df$GDP_pc_PPP, na.rm = TRUE) # na.rm stands for 'na remove'\n#&gt; [1] 15494.4\n\nThis is also the case for other functions such as min() and max().\n\n# same for max and min\nmax(df$GDP_pc_PPP) # without na.rm\n#&gt; [1] NA\nmax(df$GDP_pc_PPP, na.rm = FALSE) # na.rm FALSE\n#&gt; [1] NA\nmax(df$GDP_pc_PPP, na.rm = TRUE) # na.rm TRUE \n#&gt; [1] 122609.4\n\n# instead of TRUE or FALSE you ca write T and F\nmin(df$GDP_pc_PPP)\n#&gt; [1] NA\nmin(df$GDP_pc_PPP, na.rm = T)\n#&gt; [1] 646.86\nmin(df$GDP_pc_PPP, na.rm = F)\n#&gt; [1] NA\n\nGraphical functions will handle missingness automatically.\n\n# histogram\nhist(df$GDP_pc_PPP)\n\n\n\n\n\n# boxplot\nboxplot(df$GDP_pc_PPP)\n\n\n\n\nThis final box plot above (for GDP per capita) shows six points above the vertical line denoting the maximum. What are those?\nThey are outliers. These countries have a very high values for GDP per capita. These values are quite different than the rest as they are much higher. Such values are called outliers.\nLet’s find which countries have these highest values. To do so, I am going to sort my data frame. order() will give me the row number based on ordering of a variable.\n\n# row numbers by highest GDP_pc_PPP\norder(df$GDP_pc_PPP, decreasing = T)\n\n# get these row numbers to a row\n# so that we don't need to write this long statement again and again\nrow_nos &lt;- order(df$GDP_pc_PPP, decreasing = T)\n\n\n# First item in row_nos is the row number of the highest GDP_pc_PPP\nrow_nos[1]\n#&gt; [1] 124\n\n# get the name of the country\ndf$Country_Name[ row_nos[1] ]\n#&gt; [1] \"Qatar\"\n\n# recall that for the first six rows, you could write this\nrow_nos[c(1,2,3,4,5,6)]\n#&gt; [1] 124  82 131 111  24 158\n\n# writing c(...) is cumbersome\nc(1,2,3,4,5,6) \n#&gt; [1] 1 2 3 4 5 6\n\n# a better approach is \nseq(1,6)\n#&gt; [1] 1 2 3 4 5 6\n\n# R has a shortcut for this:\n1:6 #(from 1 to 6)\n#&gt; [1] 1 2 3 4 5 6\n\n# row numbers of the highest 6 observations (GDP_pc_PPP)\nrow_nos[1:6]\n#&gt; [1] 124  82 131 111  24 158\n\n# plug this into df$Country_Name\ndf$Country_Name[ row_nos[1:6] ]\n#&gt; [1] \"Qatar\"      \"Kuwait\"     \"Singapore\"  \"Norway\"     \"Switzerlan\"\n#&gt; [6] \"United Sta\""
  },
  {
    "objectID": "w04_funct_lib.html#pipe-operator",
    "href": "w04_funct_lib.html#pipe-operator",
    "title": "4  Functions, Libraries and Operators",
    "section": "4.1 Pipe operator",
    "text": "4.1 Pipe operator\nWe often put one function inside another function. For example, you are trying to find the mean of your exam scores.\n\n# Your exam scores:\nc(65,68,71,74, 53, 58)\n#&gt; [1] 65 68 71 74 53 58\n\n# Mean of the exam score:\nmean(c(65,68,71,74, 53, 58))\n#&gt; [1] 64.83333\n\nIn the example above, you combine you exam scores using c() and then put this into mean(). In other words, the output of c() becomes the input of mean().\nSometimes we need to repeatedly we put functions inside of other functions to create long chains. In such cases, reading and writing code might become cumbersome.\nFor example, let’s say that only the highest five exam scores are going to be considered.\n\n# Your exam scores:\nc(65,68,71,74, 53, 58)\n#&gt; [1] 65 68 71 74 53 58\n\n# Your exam scores sorted: \nsort(c(65,68,71,74, 53, 58), decreasing = T)\n#&gt; [1] 74 71 68 65 58 53\n\n# Your exam scores sorted and highest five selected\nhead(sort(c(65,68,71,74, 53, 58), decreasing = T), n = 5)\n#&gt; [1] 74 71 68 65 58\n\n\n# the mean of highest five\nmean(head(sort(c(65,68,71,74, 53, 58), decreasing = T), n = 5))\n#&gt; [1] 67.2\n\nThere is a three step chain here visualised below.\n\n\n\n\nflowchart LR\n  A(combine) --&gt; B(sort highest to lowest)\n  B --&gt; C(take the highest five exam scores)\n  C --&gt; D(take the mean)\n\n\n\n\n\nWe can use the operator |&gt; to avoid writing one function inside another. |&gt; is called the pipe operator.\n\nc(65,68,71,74, 53, 58) |&gt; sort(decreasing = T) |&gt; head(n = 5) |&gt; mean()\n#&gt; [1] 67.2\n\nWhen we use the pipe operator |&gt;, the output of a function becomes the first input of another function. In other words, it is piped.\nThis makes writing and reading the code easier."
  },
  {
    "objectID": "w04_funct_lib.html#creating-functions",
    "href": "w04_funct_lib.html#creating-functions",
    "title": "4  Functions, Libraries and Operators",
    "section": "4.2 Creating functions",
    "text": "4.2 Creating functions\nR comes with many functions, but you can write your own functions as well.\nFor example, mean() calculates the mean of a numerical vector. You could also calculate it by taking the sum of numbers and dividing it to n.\n\n# some temperature readings of a room\ntemps &lt;- c(19, 21, 17, 24, 15)\n\n# mean of temperatures using the mean function\nmean(temps)\n#&gt; [1] 19.2\n\n# calculating the mean by 'hand'\nsum(temps)/length(temps)\n#&gt; [1] 19.2\n\nCreating a function that would take a vector of numbers, sum them up and divide it to its length.\n\nfunction(x) {\n  sum(x) /  length(x)\n}\n\nHere x is a placeholder for the input. The function has one input, x, which is summed up and divided into its length.\n\n# keep this function as my_function \nmy_function &lt;- function(x) {\n  sum(x) /  length(x)\n}\n\nLet’s use our tailor-made function.\n\nmy_function(temps)\n#&gt; [1] 19.2\n\nFunctions can have more than one input.\n\nmy_other_function &lt;- function(input_one, input_two) {\n  input_one * input_two / (input_one + input_two)\n}\n\nmy_other_function(10, 40)\n#&gt; [1] 8\n\n# my_other_function(10, 40) is equivalent of:\n\n(10 * 40) / (10 + 40)\n#&gt; [1] 8"
  },
  {
    "objectID": "w04_funct_lib.html#finding-the-mode",
    "href": "w04_funct_lib.html#finding-the-mode",
    "title": "4  Functions, Libraries and Operators",
    "section": "4.3 Finding the mode",
    "text": "4.3 Finding the mode\nRecall that the mode is the most frequent observation in data. R does not have an in-built function to display the mode. Instead we can create our own function.\n\n# vector 1: fruits i ate last week:\nfruits &lt;- c(\"banana\", \"apple\", \"banana\", \"mango\", \"banana\", \"watermelon\", \"apple\")\n\n# vector 2: cups of coffee i drank last week\ncoffee &lt;- c(3, 3, 4, 1, 2, 2, 0)\n\nCalculating the mode for these vectors:\n\n# mode for fruits:\ntable(fruits)[table(fruits) == max(table(fruits))]\n#&gt; banana \n#&gt;      3\n\n# mode for coffee:\ntable(coffee)[table(coffee) == max(table(coffee))]\n#&gt; coffee\n#&gt; 2 3 \n#&gt; 2 2\n\nWe can generalize this.\n\n# home-made mode function\nmode_function &lt;- function(x){\n  table(x)[table(x) == max(table(x))]\n}\n\n# mode of fruits\nmode_function(fruits)\n#&gt; banana \n#&gt;      3\n\n# mode of coffee\nmode_function(coffee)\n#&gt; x\n#&gt; 2 3 \n#&gt; 2 2"
  },
  {
    "objectID": "w04_funct_lib.html#libraries",
    "href": "w04_funct_lib.html#libraries",
    "title": "4  Functions, Libraries and Operators",
    "section": "4.4 Libraries",
    "text": "4.4 Libraries\nR community is large and active. Many clever people are creating their own additions to R, just like we created the mode_function(). For example, there is an addition to R called DescTools which comes with a function that calculates the mode of data.\nThese additions are called libraries. You can think them as mini-applications within R.\nLet’s install and use DescTools.\n\n# install.packages(\"DescTools\")\nlibrary(DescTools)\n\n\n# Mode of fruits (using DescTools Mode() function)\nMode(fruits)\n#&gt; [1] \"banana\"\n#&gt; attr(,\"freq\")\n#&gt; [1] 3\n\n# Mode of coffee (using DescTools Mode() function)\nMode(coffee)\n#&gt; [1] 2 3\n#&gt; attr(,\"freq\")\n#&gt; [1] 2"
  },
  {
    "objectID": "w05_visualisations.html#palmer-penguins",
    "href": "w05_visualisations.html#palmer-penguins",
    "title": "5  Visualisations and tidyverse",
    "section": "5.1 Palmer Penguins",
    "text": "5.1 Palmer Penguins\nPalmer Penguins is a dataset commonly used for learning the basics of data visualisation and management. You can learn more about the fascinating story behind this dataset here: https://apreshill.github.io/palmerpenguins-useR-2022/#/title-slide.\nWe need to install R package palmerpenguins to access the data.\n\n# install the R package palmerpenguins if you have not done so before\n# installing it once is sufficient\n# install.packages(\"palmerpenguins\")\n\n# call the r package\nlibrary(palmerpenguins)\n\nOnce you initiate the R package palmerpenguins, the dataset is accessible by just typing penguins. You can think penguins like a data frame in your enviroment.\n\n# see penguins first five rows\nhead(penguins, n = 5)\n#&gt; # A tibble: 5 × 8\n#&gt;   species island    bill_length_mm bill_depth_mm flipper_l…¹ body_…² sex    year\n#&gt;   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;int&gt;   &lt;int&gt; &lt;fct&gt; &lt;int&gt;\n#&gt; 1 Adelie  Torgersen           39.1          18.7         181    3750 male   2007\n#&gt; 2 Adelie  Torgersen           39.5          17.4         186    3800 fema…  2007\n#&gt; 3 Adelie  Torgersen           40.3          18           195    3250 fema…  2007\n#&gt; 4 Adelie  Torgersen           NA            NA            NA      NA &lt;NA&gt;   2007\n#&gt; 5 Adelie  Torgersen           36.7          19.3         193    3450 fema…  2007\n#&gt; # … with abbreviated variable names ¹​flipper_length_mm, ²​body_mass_g\n\n# class of penguins\nclass(penguins)\n#&gt; [1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nDepending on your system, class(penguins) returns a tibble (tbl_df) or a data.frame. Tibble is a type of data frame used in tidyverse. We will see these shortly.\nBut first, let’s look at the dataset and have a sense of the variables.\n\n# View penguins \nView(penguins)\n\n\n# number of variables\nncol(penguins)\n#&gt; [1] 8\n\n# number of raws\nnrow(penguins)\n#&gt; [1] 344\n\n# name of the variables\nnames(penguins)\n#&gt; [1] \"species\"           \"island\"            \"bill_length_mm\"   \n#&gt; [4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n#&gt; [7] \"sex\"               \"year\"\n\nThis dataset contains information on different types of penguins. Each observation refers to a penguin. We have information about their bill length, bill depth, flipper length, and body mass, in addition to their species, the island they are living on, their sex, and the year when the measurement was taken.\nLet’s see how many different penguin species is in this dataset.\n\n# type of penguin species \ntable(penguins$species)\n#&gt; \n#&gt;    Adelie Chinstrap    Gentoo \n#&gt;       152        68       124\n\nThere are three types of penguins: Adelie, Chinstrap, Gentoo.\n\n\n\nPenguins art by Allison Horst\n\n\nSimilarly, you can check the island where penguins live.\n\n# different islands\ntable(penguins$island)\n#&gt; \n#&gt;    Biscoe     Dream Torgersen \n#&gt;       168       124        52\n\nIt is possible that some type of penguins live on a specific island whereas others are present in multiple islands. Let’s see if there is such a relationship. We can do a cross-tabulation.\n\n# table with two variables:\n# rows: first variable - island\n# columns: second variable - species\ntable(penguins$island, penguins$species)\n#&gt;            \n#&gt;             Adelie Chinstrap Gentoo\n#&gt;   Biscoe        44         0    124\n#&gt;   Dream         56        68      0\n#&gt;   Torgersen     52         0      0\n\nFrom this cross-tabulation, we can see that Adelie penguins live on all three islands where Chinstrap penguins live only on Dream Island and Gentoo lives only on Biscoe Island.\nNext, let’s continue exploring the dataset by looking at bill length and depth.\n\n\n\nPenguin bills art by Allison Horst\n\n\n\n# summary statistics of bill length\nsummary(penguins$bill_length_mm)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#&gt;   32.10   39.23   44.45   43.92   48.50   59.60       2\n\n# summary of bill depth\nsummary(penguins$bill_depth_mm)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#&gt;   13.10   15.60   17.30   17.15   18.70   21.50       2"
  },
  {
    "objectID": "w05_visualisations.html#a-simple-scatter-plot",
    "href": "w05_visualisations.html#a-simple-scatter-plot",
    "title": "5  Visualisations and tidyverse",
    "section": "5.2 A simple scatter plot",
    "text": "5.2 A simple scatter plot\nIt is quite likely that bill length and depth are closely associated. Let’s do a scatter plot and visualise both variables together. On the x-axis, I will put bill length and on the y-axis bill depth.\n\nplot(x = penguins$bill_length_mm, y = penguins$bill_depth_mm,\n     xlab = \"Bill Length\",\n     ylab = \"Bill Depth\",\n     main = \"Palmer Penguins Data: Bill Length and Depth\")\n\n\n\n\nThis is plotting in base R. It is a good graph, but it will get much harder to do in R if we want to add things such as different colours for different species. For example, how to provide summary statistics of bill length by species or island? Carrying out this in base R is possible but cumbersome. Tidyverse provides a much better set of tools for easily and systematically analysing data."
  },
  {
    "objectID": "w05_visualisations.html#tidyverse-and-ggplot2",
    "href": "w05_visualisations.html#tidyverse-and-ggplot2",
    "title": "5  Visualisations and tidyverse",
    "section": "5.3 Tidyverse and ggplot2",
    "text": "5.3 Tidyverse and ggplot2\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. - tidyverse\n\nTidyverse is not a single R package, but rather a set of R packages. To install and call all of them, you can rely on tidyverse as a shortcut.\n\n# install packages\ninstall.packages(\"tidyverse\")\n\n\n# call the library\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.0     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ ggplot2   3.4.1     ✔ tibble    3.1.8\n#&gt; ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n#&gt; ✔ purrr     1.0.2     \n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors"
  },
  {
    "objectID": "w05_visualisations.html#goal-scatter-plot-of-bill-length-and-depth-by-species",
    "href": "w05_visualisations.html#goal-scatter-plot-of-bill-length-and-depth-by-species",
    "title": "5  Visualisations and tidyverse",
    "section": "5.4 Goal: Scatter plot of bill length and depth by species",
    "text": "5.4 Goal: Scatter plot of bill length and depth by species\nOur goal is to create the graph below. We are going to use ggplot() to achieve this, which is a package in the tidyverse family.\n\n\n\n\n\nCreating a graph with ggplot is a step by step process. First, we start by mapping the x and y axes.\n\nggplot(data = penguins,\n       mapping = aes(x = bill_length_mm,\n                     y = bill_depth_mm))\n\n\n\n\nThis creates an empty plot with our variables of interest on each axis. aes stands for aesthetic. It is called aesthetic because it is related to the appearance of the graph.\nNext, we will add data points by geom_point(). Adding features to a ggplot() is a little bit strange because we use + notation, which is different to many applicaytion in base R. You can think this as a lingual peculiarity of ggplot.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm\n                )\n) +\n  geom_point()\n\n\n\n\nWe are getting closer to our goal. Next, we need to distinguish Penguins by their species. We can show each species with a different shape. Again, we are going to use aes() because we are going to change the shape of data points according to species.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm\n                )\n) +\n  geom_point(mapping = aes(shape = species))\n#&gt; Warning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\nYou might be wondering why we put aes() inside geom_point, but not the main ggplot function. Let’s try that alternative.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm,\n                shape = species\n                )\n) +\n  geom_point()\n\n\n\n\nAs you can see, outputs are the same for both approaches. Second approach, putting shape under the main ggplot function is called a global option, because it is defined in a higher hierarchy. Defining shape under geom_point() would be a local option, because it is defined specifically for points. The behaviour is the same because it does not matter at which level you define the shape.\n\n\n\n\n\n\nWarning\n\n\n\n\n\nLocal options may override global options. For example, if you accidentally put two different shapes to aesthetics, local aes will be displayed.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm,\n                shape = species # shape defined as species\n                ) \n) +\n  geom_point(mapping = aes(shape = island)) # shape defined as island\n\n\n\n\nThe output has shapes by island instead of species, because local aes under geom_poit() overrides the aes() inside ggplot().\nThis is for demonstration purposes. In general, you should avoid putting conflicting options.\n\n\n\nWe also want to display points with different colors according to species.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm)\n) +\n  geom_point(mapping = aes(shape = species, \n                           color = species))\n\n\n\n\nFinal step is to add the labels.\n\nggplot(\n  data = penguins,\n  mapping = aes(x = bill_length_mm, \n                y = bill_depth_mm)\n) +\n  geom_point(mapping = aes(shape = species, \n                           color = species)\n  ) + \n  labs(\n    title = \"Bill length and bill depth\",\n    subtitle = \"Measurements for Adelie, Chinstrap, and Gentoo Penguins\",\n    x = \"Bill length (mm)\", \n    y = \"Bill depth (mm)\",\n    color = \"Penguin\",\n    shape = \"Penguin\"\n  )"
  },
  {
    "objectID": "w05_visualisations.html#mean-body-mass-by-species",
    "href": "w05_visualisations.html#mean-body-mass-by-species",
    "title": "5  Visualisations and tidyverse",
    "section": "5.5 Mean body mass by species",
    "text": "5.5 Mean body mass by species\nFinding the mean of body_mass_g is a straightforward task.\n\n# mean of body mass (in grams)\nmean(penguins$body_mass_g, na.rm = T)\n#&gt; [1] 4201.754\n\nWhat if we want to find the mean by species? Doing this in base R can be long, confusing, and cumbersome. This is exactly why our friends in R Studio created the tidyverse family. We can use it to simplify the task.\nBut first we need to learn the basics of tidyverse linguistics.\nWe usually start with a data frame in tidyverse, which is also called a tibble (tidyverse specific data frame). For example, tidyverse’s summarize() is a useful function whose purpose is to provide a summary statistic. It takes a data frame, and you can calculate the summary statistic you wish.\n\npenguins |&gt;\n  summarize(statistics_i_wish = mean(body_mass_g, na.rm = T))\n#&gt; # A tibble: 1 × 1\n#&gt;   statistics_i_wish\n#&gt;               &lt;dbl&gt;\n#&gt; 1             4202.\n\nYou can use it to calculate more than one statistics.\n\npenguins |&gt;\n  summarize(mean_mass_g = mean(body_mass_g, na.rm = T),\n            mean_mass_kg = mean(body_mass_g, na.rm = T) / 1000,\n            number_of_penguins = n()\n            )\n#&gt; # A tibble: 1 × 3\n#&gt;   mean_mass_g mean_mass_kg number_of_penguins\n#&gt;         &lt;dbl&gt;        &lt;dbl&gt;              &lt;int&gt;\n#&gt; 1       4202.         4.20                344\n\nThis is without any grouping. I would like to calculate the mean body mass by species. We can use group_by() available in tidyverse to group the data. We can use this jointly with summarise to get a summary statistic, such as the mean.\n\npenguins |&gt;\n  group_by(species) |&gt;\n  summarize(mean_mass_g = mean(body_mass_g, na.rm = T),\n            mean_mass_kg = mean(body_mass_g, na.rm = T) / 1000,\n            number_of_penguins = n()\n            )\n#&gt; # A tibble: 3 × 4\n#&gt;   species   mean_mass_g mean_mass_kg number_of_penguins\n#&gt;   &lt;fct&gt;           &lt;dbl&gt;        &lt;dbl&gt;              &lt;int&gt;\n#&gt; 1 Adelie          3701.         3.70                152\n#&gt; 2 Chinstrap       3733.         3.73                 68\n#&gt; 3 Gentoo          5076.         5.08                124\n\nThe output is grouped by species as we wanted. We can now see the average mass of penguins according to different species. On average, Gentoo is the heaviest."
  },
  {
    "objectID": "w06_correlation.html#numerical-and-visual-summary-of-female-life-expectancy",
    "href": "w06_correlation.html#numerical-and-visual-summary-of-female-life-expectancy",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.1 Numerical and visual summary of female life expectancy",
    "text": "6.1 Numerical and visual summary of female life expectancy\nFemale life expectancy is measured in calendar years and straightforward to understand.\nStart with a numerical summary.\n\n\nReveal the code\n# numerical summary of Life_exp_female (Female Life Expectancy)\nsummary(df$Life_exp_female)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#&gt;   48.88   64.41   74.91   71.94   78.73   86.30\n\n\nIt looks like there is no missing data points in Life_exp_female. We know this because summary also reports how many data points are missing when there missingness.\nThe lowest female life expectancy in 2010 was 48.88 years, which is dismally low. The highest female life expectancy is 86.30. You might be curious to see which countries are these.\nIt is also a good idea to check and report the standard deviation.\nFind the standard deviation.\n\n\nReveal the code\n# standard deviation of Female Life Expectancy:\nsd(df$Life_exp_female, na.rm = T)\n#&gt; [1] 9.353926\n\n\nLet’s also visually explore the data. Histogram and boxplot are both nice ways to visually summarize data. We are going to use ggplot for this purpose, so it is a good idea to load it as well (alternatively, load whole tidyverse).\n\n# load ggplot \nlibrary(ggplot2)\n\nContinue with a histogram. Try to do it yourself (give yourself at least a few minutes).\n\n\nReveal the code\n# histogram:\nggplot(data = df, mapping = aes(x = Life_exp_female)) +\n  geom_histogram(binwidth = 2.5) +\n  labs(title = \"World in 2010\",\n       subtitle = \"Female Life Expectancy\",\n       x = \"Female Life Expectancy (in years)\",\n       y = \"Number of Countries\")\n\n\n\n\n\nNext, let’s also do a boxplot. Again, try to do it yourself.\n\n\nReveal the code\nggplot(data = df, mapping = aes(y = Life_exp_male, x = \"\")) +\n  geom_boxplot() +\n  scale_x_discrete( ) +\n  labs(title = \"World in 2010\",\n       x = \"Female Life Expectancy in 2010\",\n       y = \"Female Life Expectancy (in years)\")"
  },
  {
    "objectID": "w06_correlation.html#numerical-and-visual-summary-of-infant-mortality",
    "href": "w06_correlation.html#numerical-and-visual-summary-of-infant-mortality",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.2 Numerical and visual summary of infant mortality",
    "text": "6.2 Numerical and visual summary of infant mortality\nInfant Mortality Rate is commonly measured as the number of infant deaths out of 1000 births. Infant is defined as a baby younger than one-year old.\nAgain, let’s start with a numerical summary.\n\n\nReveal the code\n# Summary\nsummary(df$Infant_Mortality_Rate)\n#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n#&gt;    2.00    7.50   19.20   29.25   48.10  108.40       1\n\n\nThe lowest infant mortality rate is 2 infants out of 1000 whereas the highest is 108.40. There is a huge difference between infant mortality rate across countries. This is visible from the range and the inter-quartile range.\nNote that the information on the infant mortality rate of one countriy is not available. We know this thanks to summary output above.\nFind the country with missing infant mortality rate.\nFind the countries with the lowest and highest infant mortality rates.\nFind the countries with the lowest and highest infant mortality rates.\nWe mentioned that infant mortality rate has high dispersion. We should calculate and report the standard deviation as well.\n\n\nReveal the code\n# standard deviation of infant mortality rate\nsd(df$Infant_Mortality_Rate, na.rm = T)\n#&gt; [1] 25.89212\n\n\nNext, let’s continue with a histogram. We should expect to receive a warning message saying that missing observations are removed.\n\n\nReveal the code\n# Histogram\nggplot(df, aes(x = Infant_Mortality_Rate)) + \n  geom_histogram(binwidth = 3) +\n  labs(title = \"World in 2020\",\n       subtitle = \"Infant mortality rate\",\n       x = \"Infant Mortality\",\n       y = \"Mortality rate (out of 1000 infants)\")\n#&gt; Warning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nContinue with a boxplot.\n\n\nReveal the code\n# box plot\nggplot(df, aes(y = Infant_Mortality_Rate)) +\n  geom_boxplot() +\n  scale_x_discrete() +\n  labs(title = \"World in 2020\",\n       subtitle = \"Infant mortality rate\",\n       y = \"Mortality rate (out of 1000 infants)\",\n       x = \"Infant Mortality\"\n       )\n#&gt; Warning: Removed 1 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "w06_correlation.html#association-between-infant-mortality-and-female-life-expectancy",
    "href": "w06_correlation.html#association-between-infant-mortality-and-female-life-expectancy",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.3 Association between Infant Mortality and Female Life Expectancy",
    "text": "6.3 Association between Infant Mortality and Female Life Expectancy\nIt is time to explore the association between the two variables. As we have mentioned earlier, a scatter plot is a good place to start. I am not analysing a causal relationship (recall the causality lecture!). Instead, I am just looking at a possible relationship. It is quite obvious that both the female life expectancy and the infant mortality rate is affected by some other underlying factors, such as the quality and accessibility of healthcare in the country, hygiene standarts, general economic development.\nAlthough we expect to see a strong association between the two variables, we do not think that it is a causal relationship. We are not trying to explain one variable with the other. Therefore, it does not really matter to which access we put our variable of interest.\n\n# Scatterplot \nggplot(df, aes(x = Infant_Mortality_Rate, y = Life_exp_female)) +\n  geom_point() + \n  labs(title = \"World in 2010\",\n       x = \"Infant Mortality Rate\",\n       y = \"Female Life Expectancy\")\n#&gt; Warning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\nDo you see a pattern?\nNext week, we will start working on regression, but for a sneak peek, let’s draw the OLS regression line.\n\n# add regression line to the scatter plot\nggplot(df, aes(x = Infant_Mortality_Rate, y = Life_exp_female)) +\n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  labs(title = \"World in 2010\",\n       x = \"Infant Mortality Rate\",\n       y = \"Female Life Expectancy\")"
  },
  {
    "objectID": "w06_correlation.html#correlation-coefficient",
    "href": "w06_correlation.html#correlation-coefficient",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.4 Correlation Coefficient",
    "text": "6.4 Correlation Coefficient\nNext, we are going to calculate the Pearson correlation coefficient between the two variables.\nRecall that Pearson correlation coefficient is a measure of linear relationship between two numerical variables (lab lecture on 13 November 2023). It can take values between -1 and 1. It is a standardized version of co-variance, which creates the boundries of -1 and 1.\nBefore revisiting the details, let’s learn how to ask R to calculate it for us. It is pretty straightforward.\n\n# correlation coefficient between two variables\ncor(df$Life_exp_female, df$Infant_Mortality_Rate, use = \"pairwise\")\n#&gt; [1] -0.9420862\n\nThis figure indicates a very strong negative linear relationship between Life_exp_female and Infant_Mortality_Rate.\nWe need to add the option use = \"pairwise\" because there is at least one missing value. Pairwise here is a shorthand for ‘pairwise complete observations’."
  },
  {
    "objectID": "w06_correlation.html#correlation-matrix",
    "href": "w06_correlation.html#correlation-matrix",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.5 Correlation Matrix",
    "text": "6.5 Correlation Matrix\nWe might be interested in exploring correlation coefficient of several variables. For example, Life_exp_male is life expectancy of males. It is likely that there is a strong correlated between Life_exp_male and Life_exp_female. Similarly, HIV (the rate of HIV in the country), and GDP_pc_PPP (GDP per capita in Purchasing Power Parity) are also correlated with life expectancy outcomes. Finally, v2x_polyarchy is the VDem’s Electoral Democracy Index, which is a measurement for the level of democracy in the country. All these variables are numerical, thus it is possible to calculate the correlation coefficient.\nWe could calculate each pairs correlation coefficient.\n\n# correlation of Life_exp_male and Life_exp_female\ncor(df$Life_exp_female, df$Life_exp_male)\n#&gt; [1] 0.9741536\n\nHowever, this would become burdensome quite quickly as the number of variables increase. Instead, we can create a correlation matrix.\ncor() can take a data frame or matrix but all of the variables should be numerical. If we try to put df into cor(), we will get an error message because of string and nominal variables.\n\ncor(df)\n#&gt; Error in cor(df): 'x' must be numeric\n\nTherefore, I need to select a bunch of numerical variables. You could do this in base R, but the select() function in tidyverse is a much better choice. Let’s load the tidyverse.\n\nlibrary(tidyverse)\n#&gt; ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n#&gt; ✔ dplyr     1.1.0     ✔ readr     2.1.4\n#&gt; ✔ forcats   1.0.0     ✔ stringr   1.5.0\n#&gt; ✔ lubridate 1.9.2     ✔ tibble    3.1.8\n#&gt; ✔ purrr     1.0.2     ✔ tidyr     1.3.0\n#&gt; ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n#&gt; ✖ dplyr::filter() masks stats::filter()\n#&gt; ✖ dplyr::lag()    masks stats::lag()\n#&gt; ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nAlso, I am going to use pipes (|&gt;) to make it easier. Finally, I am going to round the output to three decimal points to keep things easier to read.\n\ndf |&gt; \n  select(Life_exp_female, Life_exp_male, \n         Infant_Mortality_Rate, HIV, GDP_pc_PPP,\n         v2x_polyarchy, UN_vote_PctAgreeUS, \n         UN_vote_PctAgreeRUSSIA, \n         UN_vote_PctAgreeChina) |&gt; # selecting some variables of interest \n  cor(use = \"pairwise\") |&gt; # correlation (input comes from the pipe)\n  round(3) # rounding to three decimal points\n#&gt;                        Life_exp_female Life_exp_male Infant_Mortality_Rate\n#&gt; Life_exp_female                  1.000         0.974                -0.942\n#&gt; Life_exp_male                    0.974         1.000                -0.901\n#&gt; Infant_Mortality_Rate           -0.942        -0.901                 1.000\n#&gt; HIV                             -0.511        -0.539                 0.351\n#&gt; GDP_pc_PPP                       0.610         0.643                -0.580\n#&gt; v2x_polyarchy                    0.476         0.466                -0.429\n#&gt; UN_vote_PctAgreeUS               0.446         0.446                -0.402\n#&gt; UN_vote_PctAgreeRUSSIA          -0.356        -0.398                 0.306\n#&gt; UN_vote_PctAgreeChina           -0.540        -0.519                 0.506\n#&gt;                           HIV GDP_pc_PPP v2x_polyarchy UN_vote_PctAgreeUS\n#&gt; Life_exp_female        -0.511      0.610         0.476              0.446\n#&gt; Life_exp_male          -0.539      0.643         0.466              0.446\n#&gt; Infant_Mortality_Rate   0.351     -0.580        -0.429             -0.402\n#&gt; HIV                     1.000     -0.191        -0.112             -0.172\n#&gt; GDP_pc_PPP             -0.191      1.000         0.295              0.456\n#&gt; v2x_polyarchy          -0.112      0.295         1.000              0.523\n#&gt; UN_vote_PctAgreeUS     -0.172      0.456         0.523              1.000\n#&gt; UN_vote_PctAgreeRUSSIA  0.112     -0.316        -0.487             -0.654\n#&gt; UN_vote_PctAgreeChina   0.229     -0.405        -0.624             -0.871\n#&gt;                        UN_vote_PctAgreeRUSSIA UN_vote_PctAgreeChina\n#&gt; Life_exp_female                        -0.356                -0.540\n#&gt; Life_exp_male                          -0.398                -0.519\n#&gt; Infant_Mortality_Rate                   0.306                 0.506\n#&gt; HIV                                     0.112                 0.229\n#&gt; GDP_pc_PPP                             -0.316                -0.405\n#&gt; v2x_polyarchy                          -0.487                -0.624\n#&gt; UN_vote_PctAgreeUS                     -0.654                -0.871\n#&gt; UN_vote_PctAgreeRUSSIA                  1.000                 0.752\n#&gt; UN_vote_PctAgreeChina                   0.752                 1.000\n\nWhat do you see? Anything surprising? Anything expected? Try to interpret this output.\n\n\n\n\n\n\nAlternative (Base R and no pipe)\n\n\n\n\n\nIn case you are confused with this code, this is the alternative without the pipe and tidyverse.\n\n# variable names:\nvariables_of_interest &lt;- c(\"Life_exp_female\", \n                           \"Life_exp_male\", \n                           \"Infant_Mortality_Rate\", \n                           \"HIV\", \n                           \"GDP_pc_PPP\",\n                           \"v2x_polyarchy\", \n                           \"UN_vote_PctAgreeUS\", \n                           \"UN_vote_PctAgreeRUSSIA\", \n                           \"UN_vote_PctAgreeChina\") \n\n# smaller data frame with only variables of interest:\ndf_light &lt;- df[, variables_of_interest]\n\n# correlation matrix with three decimal points\nround(cor(df_light, use = \"pairwise\"), 3)"
  },
  {
    "objectID": "w06_correlation.html#exercises",
    "href": "w06_correlation.html#exercises",
    "title": "6  Association Between Two Numerical Variables",
    "section": "6.6 Exercises",
    "text": "6.6 Exercises\n\n6.6.1 Hours of study and marks\nYour task is to calculate the correlation between study hours and marks as shown below.\n\nMarks\n\n\nX (Study Hour)\nY (Mark)\n\n\n\n\n1\n55\n\n\n1\n45\n\n\n1\n52\n\n\n1\n48\n\n\n3\n61\n\n\n3\n59\n\n\n3\n65\n\n\n3\n55\n\n\n\nFirst, create a data frame with appropriate variable names.\n\n\nReveal the code\n# data frame for exercise 1 (ex1):\n\nex1 &lt;- data.frame(study_hour = c(rep(1,4), rep(3,4)),\n           mark = c(55, 45, 52, 48, 61, 59, 65, 55)\n           )\n\n\nNext, draw a scatterplot like the one below.\n\n\n\n\n\n\n\nReveal the code\nggplot(ex1, aes(x = study_hour, y = mark)) +\n  geom_point() +\n  labs(title = \"Study Hour and Marks Received\",\n       x = \"Hours of Study\",\n       y = \"Mark\") \n\n\nCalculate the correlation coefficient.\n\n\nReveal the code\ncor(ex1)\n#&gt;            study_hour      mark\n#&gt; study_hour  1.0000000 0.8032193\n#&gt; mark        0.8032193 1.0000000\n\n\n\n\n6.6.2 Challenge\nCalculate the correlation co-efficient ‘by hand’. With by hand, I mean not using functions such as cor(), var(), cov(). Instead, you can calculate all the steps like we did in the lecture using only simple R code. The goal is to follow the formula.\nLet’s remind ourselves the formulas. Starting with correlation coefficient:\n\\[cor(X,Y) = \\frac{cov(X,Y)}{\\sigma_X*\\sigma_Y} \\] \\(cov(X,Y)\\) stands for covariance between X and Y, which can be calculated with the following formula:\n\\[cov(X,Y) = \\frac{\\sum_{i=1}^{n}{(x_i -\\bar{x}) * (y_i - \\bar{y})}}{n-1}\\] Also, recall the formula for standard deviation (\\(\\sigma\\)):\n\\[\\sigma_X = var(X)^2 = \\sqrt{\\frac{\\sum{(x_i - \\bar{x})^2}}{n-1}}\\] You can use functions such as mean(), length(), sqrt().\nMake sure to check your final result and mid-steps using var(), cov(), and cor().\n\n\n\n\n\n\nNote\n\n\n\n\n\nThis is an exercise to understand how variance, covariance and correlation is calculated. In reality, you wouldn’t calculate it in such a way, but tell R to calculate it for you."
  },
  {
    "objectID": "w07_regression.html#starting-routine",
    "href": "w07_regression.html#starting-routine",
    "title": "7  Bivariate Regression",
    "section": "7.1 Starting Routine",
    "text": "7.1 Starting Routine\nWe are going to analyse Putnam’s data. First, check what you have in your environment using ls().\n\n# See what you have in the environment. \nls()\n#&gt; [1] \"a\"                                              \n#&gt; [2] \"a_squared\"                                      \n#&gt; [3] \"definitely_not_needed_for_this_session\"         \n#&gt; [4] \"df_that_will_probably_confuse_me_if_not_removed\"\n#&gt; [5] \"leftover_object\"                                \n#&gt; [6] \"some_data_from_some_other_time\"\n\n# I have no use of any of these. Let's remove them.\nrm(list = ls())\n\nNext, load ggplot because we are going to need it for visualisation.\n\nlibrary(ggplot2)\n\nLet’s continue with loading Putnam’s data. It can be downloaded from module Blackboard page. Keep your files tidy and put it under your data directory.\n\n# load the data (df stands for data frame)\ndf &lt;- read.csv(\"data/putnam.csv\")\n\n# display data\ndf\n#&gt;    Region InstPerform CivicCommunity NorthSouth EconModern\n#&gt; 1      Ab         7.5            8.0      South        7.0\n#&gt; 2      Ba         7.5            4.0      South        3.0\n#&gt; 3      Cl         1.5            1.0      South        3.0\n#&gt; 4      Cm         2.5            2.0      South        6.5\n#&gt; 5      Em        16.0           18.0      North       13.0\n#&gt; 6      Fr        12.0           17.0      North       14.5\n#&gt; 7      La        10.0           13.0      North       12.5\n#&gt; 8      Li        11.0           16.0      North       15.5\n#&gt; 9      Lo        11.0           17.0      North       19.0\n#&gt; 10     Ma         9.0           15.5      North       10.5\n#&gt; 11     Mo         6.5            3.5      South        2.5\n#&gt; 12     Pi        13.0           15.5      North       17.0\n#&gt; 13     Pu         5.5            3.5      South        4.0\n#&gt; 14     Sa         5.5            8.5      South        8.5\n#&gt; 15     Si         4.5            3.5      South        5.5\n#&gt; 16     To        13.0           17.5      North       14.5\n#&gt; 17     Tr        11.0           18.0      North       12.5\n#&gt; 18     Um        15.0           15.5      North       11.0\n#&gt; 19     Va        10.0           15.0      North       15.0\n#&gt; 20     Ve        11.0           15.0      North       13.5\n\n\n# Probably a better option of seeing data in R Studio:\n#View(df)"
  },
  {
    "objectID": "w07_regression.html#scatter-plot",
    "href": "w07_regression.html#scatter-plot",
    "title": "7  Bivariate Regression",
    "section": "7.2 Scatter Plot",
    "text": "7.2 Scatter Plot\nThis week, we are interested in InstPerform and CivicCommunity. We are trying to explain InstPerform (our outcome variable) with CivicCommunity (our explanatory variable).\nLet’s create a scatter plot.\n\nggplot(data = df, aes(x = CivicCommunity, y = InstPerform)) +\n  geom_point() + \n  labs(y = \"Institutional Performance\",\n        x = \"Civic Community Score\"\n        )\n\n\n\n\nIt is also possible to use region labels rather than just points. Use the Region variable to label each point accordingly.\n\nggplot(data = df, aes(x = CivicCommunity, y = InstPerform)) +\n  geom_text(aes(label = Region)) + \n  labs(y = \"Institutional Performance\",\n        x = \"Civic Community Score\"\n        )"
  },
  {
    "objectID": "w07_regression.html#regression",
    "href": "w07_regression.html#regression",
    "title": "7  Bivariate Regression",
    "section": "7.3 Regression",
    "text": "7.3 Regression\nNext, we are going to run a regression. Recall the lecture for generic formula to draw a regression line.\n\\[ y = \\alpha + \\beta * x \\]\nHere, the outcome variable (Y) is InstPerform. Explanatory variable (X) is CivicCommunity.\n\n# run linear regression: (lm stands for linear model)\nlm(formula = InstPerform ~ CivicCommunity, data = df)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = InstPerform ~ CivicCommunity, data = df)\n#&gt; \n#&gt; Coefficients:\n#&gt;    (Intercept)  CivicCommunity  \n#&gt;         2.7112          0.5673\n\nThe results of the regression is directly displayed. The intercept refers to \\(\\alpha\\), which is 2.71. The slope, which is also called the regression coefficient or \\(\\beta\\) for CivicCommunity is 0.57.\nWe can say that one unit increase in CivicCommunity is associated with 0.57 unit increase in InstPerform.\nAn alternative way to run the same code is the following.\n\n# Alternative code\nlm(df$InstPerform ~ df$CivicCommunity)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = df$InstPerform ~ df$CivicCommunity)\n#&gt; \n#&gt; Coefficients:\n#&gt;       (Intercept)  df$CivicCommunity  \n#&gt;            2.7112             0.5673\n\nThey are equivalent. Feel free to use the version that you find easiest.\nIt is a good idea to put your regression results into an object. lm() has generated much more than it displays on screen.\n\n# regression model (m1: model 1)\nm1 &lt;- lm(InstPerform ~ CivicCommunity, data = df)\n\nYou can use summary() to check the output in the object m1.\n\n# summary of model 1:\nsummary(m1)\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = InstPerform ~ CivicCommunity, data = df)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -2.5043 -1.3481 -0.2087  0.9764  3.4957 \n#&gt; \n#&gt; Coefficients:\n#&gt;                Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)     2.71115    0.84443   3.211  0.00485 ** \n#&gt; CivicCommunity  0.56730    0.06552   8.658 7.81e-08 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 1.789 on 18 degrees of freedom\n#&gt; Multiple R-squared:  0.8064, Adjusted R-squared:  0.7956 \n#&gt; F-statistic: 74.97 on 1 and 18 DF,  p-value: 7.806e-08\n\nOverall output is slightly longer than what we need. Let’s focus on some parts that we are usually interested in:\n\nEstimate is the respective estimates for the coefficients.\nStd. Error is the standard error. It quantifies the uncertainty in our estimates.\nPr(&gt;|t|) refers to statistical significance and is related to uncertainty in our estimations. A value below 0.05 is often considered as statistically significant, which indicates that the relationship is unlikely due to sampling variability.\nAdjusted R-squared refers to how good the overall model fit. It is a value between 0 and 1. 0.80 means, the 80% of the variation in InstPerform can be explained with CivicCommunity.\n\nA lot of info is provided here, but we may not need all of it. Let’s just have a simplified table. To have a publication-quality table output, we use the texreg package. To install it, make sure to run the code install.packages(\"texreg\").\n\nlibrary(texreg)\n#&gt; Warning: package 'texreg' was built under R version 4.2.3\n#&gt; Version:  1.39.3\n#&gt; Date:     2023-11-09\n#&gt; Author:   Philip Leifeld (University of Essex)\n#&gt; \n#&gt; Consider submitting praise using the praise or praise_interactive functions.\n#&gt; Please cite the JSS article in your publications -- see citation(\"texreg\").\n\nUse screenreg().\n\n# texreg's screenreg function displays regression results on the screen.\nscreenreg(m1)\n#&gt; \n#&gt; =========================\n#&gt;                 Model 1  \n#&gt; -------------------------\n#&gt; (Intercept)      2.71 ** \n#&gt;                 (0.84)   \n#&gt; CivicCommunity   0.57 ***\n#&gt;                 (0.07)   \n#&gt; -------------------------\n#&gt; R^2              0.81    \n#&gt; Adj. R^2         0.80    \n#&gt; Num. obs.       20       \n#&gt; =========================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\nwordreg(m1, \"my_output.docx\")\n\ntexreg package provides many options. You can see the full documentation of texreg here: https://cran.r-project.org/web/packages/texreg/texreg.pdf\nYou can also use R help files, for example: ?wordreg()."
  },
  {
    "objectID": "w07_regression.html#visualisation",
    "href": "w07_regression.html#visualisation",
    "title": "7  Bivariate Regression",
    "section": "7.4 Visualisation",
    "text": "7.4 Visualisation\nLet’s add a regression line to the scatter plot. Also, save our output.\n\nggplot(data = df, aes(x = CivicCommunity, y = InstPerform)) +\n  geom_point() + \n  geom_smooth(method = \"lm\") +\n  labs(y = \"Institutional Performance\",\n        x = \"Civic Community Score\"\n        )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n# save the plot:\nggsave(file=\"model1.pdf\", width=8, height=6)\n#&gt; `geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "w07_regression.html#exercise",
    "href": "w07_regression.html#exercise",
    "title": "7  Bivariate Regression",
    "section": "7.5 Exercise",
    "text": "7.5 Exercise\nUsing world_in_2010.csv, carry out the regression as formulated below.\n\\[ FemaleLifeExpectancy = \\alpha + \\beta * InfantMortalityRate \\] Interpret the output. Provide appropriate visualisations."
  },
  {
    "objectID": "w07_regression.html#summary",
    "href": "w07_regression.html#summary",
    "title": "7  Bivariate Regression",
    "section": "7.6 Summary",
    "text": "7.6 Summary\nIn reading a regression table, make sure to follow these steps.\n\nIdentify the regression line (equation):\n\n\\[ Y = \\_\\_\\_ +  \\_\\_\\_   * X\\]\n\nIdentify the sign of your coefficients (\\(\\alpha\\) and \\(\\beta\\)) and interpret them:\n\n\nscreenreg(m1)\n#&gt; \n#&gt; =========================\n#&gt;                 Model 1  \n#&gt; -------------------------\n#&gt; (Intercept)      2.71 ** \n#&gt;                 (0.84)   \n#&gt; CivicCommunity   0.57 ***\n#&gt;                 (0.07)   \n#&gt; -------------------------\n#&gt; R^2              0.81    \n#&gt; Adj. R^2         0.80    \n#&gt; Num. obs.       20       \n#&gt; =========================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\nCoefficients: \\(\\alpha = 2.71\\) and \\(\\beta = 0.57\\).\n\\(\\alpha = 2.71\\) means that when \\(X\\) is 0, the predicted value of \\(Y\\) is 2.71.\n\\(\\beta = 0.57\\) means that a one-unit increase in \\(X\\) is associated with an increase of 0.57 in \\(Y\\).\nThis is sometimes called the marginal effect of \\(X\\) (the size of \\(\\beta\\)). The word effect here is kind of a misnomer because it encourages you to think in terms of cause and effect. However, it is a commonly used word, so we are going to use it as well, but do not think this in terms of causality."
  },
  {
    "objectID": "w07_regression.html#prediction",
    "href": "w07_regression.html#prediction",
    "title": "7  Bivariate Regression",
    "section": "7.7 Prediction",
    "text": "7.7 Prediction\nRunning this regression, we created a statistical model which guesses the expected \\(Y\\) values when we give some \\(X\\) values. In this respect, the regression line is the prediction line. You can think regression as predictive modelling.\nFor a given value of \\(X\\), the line gives us the predicted value of \\(Y\\), or simply \\(\\hat{Y}\\). \\(\\hat{Y}\\) reads as \\(Y \\  hat\\) and means the \\(predicted\\ value\\  of\\ Y\\).\n\\[When\\ X = 0 \\ \\ \\rightarrow\\ \\ \\ \\hat{Y} = 2.71 + 0 * 0.57 = 2.71 \\] \\[When\\ X = 1 \\ \\ \\rightarrow \\ \\ \\hat{Y} = 2.71 + 1 * 0.57 = 3.28\\]\n\\[When\\ X = 1 \\ \\ \\rightarrow \\ \\ \\hat{Y} = 2.71 + 2 * 0.57 = 3.85\\] \\[...\\]\n\n7.7.1 Predict function in R\nYou can use predict() to get \\(\\hat{Y}\\) for your regression model. The input of predict() is our regression output, which is stored in the object m1.\n\npredict(object = m1)\n#&gt;         1         2         3         4         5         6         7         8 \n#&gt;  7.249547  4.980350  3.278452  3.845751 12.922540 12.355241 10.086044 11.787942 \n#&gt;         9        10        11        12        13        14        15        16 \n#&gt; 12.355241 11.504292  4.696700 11.504292  4.696700  7.533197  4.696700 12.638891 \n#&gt;        17        18        19        20 \n#&gt; 12.922540 11.504292 11.220642 11.220642\n\nNote that 20 predictions are printed. This is equal to the number of observations in our data. You can save this in a variable in df.\n\n# predicted values of Institutional Performance according to m1\ndf$m1_yhat &lt;- predict(object = m1)\n\n# View(df)\n\nLet’s visualize these predicted values of Institutional Performance. They will form a line.\n\nggplot(df, aes(x = CivicCommunity, y = m1_yhat)) +\n  geom_point(color = \"red\") + \n  labs(x = \"Civic Community\", \n       y = \"Predicted values of Institutional Performance\")\n\n\n\n\nIndeed, these predicted values are all on the regression line.\n\nggplot(data = df, aes(x = CivicCommunity, y = InstPerform)) +\n  geom_smooth(method = \"lm\", se = F, color = \"black\") +\n  geom_point(aes(x = CivicCommunity, y = m1_yhat), \n             color = \"red\", size = 4) + \n  labs(y = \"Institutional Performance\",\n        x = \"Civic Community Score\"\n        )\n#&gt; `geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n7.7.2 Prediction with new values of x\nImagine that we have a new region with a Civic Community Score of 10 and we would like to predict its likely Institutional Performance using our regression model.\n\n\n\n\n\nFigure 7.1: Regression line\n\n\n\n\nLet’s remind ourselves the regression model:\n\\[\\hat{y} = \\alpha + \\beta * x \\]\nSo when CivicCommunity is 10:\n\\[x = 10 \\ \\ \\rightarrow \\ \\ \\hat{y} = \\alpha + 10 * \\beta \\]\nWe have estimated the model coefficients, namely \\(\\alpha\\) and \\(\\beta\\). You can directly go into model coefficients using the approach below.\n\n# model coefficients (m1):\nm1$coefficients\n#&gt;    (Intercept) CivicCommunity \n#&gt;      2.7111528      0.5672993\n\n# m1 alpha:\nm1$coefficients[1]\n#&gt; (Intercept) \n#&gt;    2.711153\n\n# m1 beta:\nm1$coefficients[2]\n#&gt; CivicCommunity \n#&gt;      0.5672993\n\nWe could ask R to calculate \\(\\alpha + 10 * \\beta\\) by writing each of the constituent parts:\n\nm1$coefficients[1] + 10 * m1$coefficients[2]\n#&gt; (Intercept) \n#&gt;    8.384146\n\nHowever, this is not necessary because predict() function is capable of handling different \\(X\\) values that we may plug in. We need to use the option newdata, which takes a data frame.\n\n# Predict yhat (model: m1) when  x = 10\npredict(m1, newdata = data.frame(CivicCommunity = 10))\n#&gt;        1 \n#&gt; 8.384146\n\n\n\n\n\n\nFigure 7.2: Regression line\n\n\n\n\nPredicted Institutional Performance is 8.38 when Civic Community is 10, according to our regression model (m1).\nWe can also give multiple \\(x\\) values to predict() function.\n\n# Predict yhat (model: m1) when  x is 1,2,3,......18, 19, 20\nx_values &lt;- data.frame(CivicCommunity = seq(1, 20, 1)) # create x values\n\n# predict:\npredict(m1, x_values)\n#&gt;         1         2         3         4         5         6         7         8 \n#&gt;  3.278452  3.845751  4.413051  4.980350  5.547649  6.114949  6.682248  7.249547 \n#&gt;         9        10        11        12        13        14        15        16 \n#&gt;  7.816847  8.384146  8.951445  9.518745 10.086044 10.653343 11.220642 11.787942 \n#&gt;        17        18        19        20 \n#&gt; 12.355241 12.922540 13.489840 14.057139"
  },
  {
    "objectID": "w07_regression.html#prediction-error",
    "href": "w07_regression.html#prediction-error",
    "title": "7  Bivariate Regression",
    "section": "7.8 Prediction Error",
    "text": "7.8 Prediction Error\nPredicted institutional performance \\((\\hat{y})\\) from model 1 are not perfect – and they should not me. These are estimates after all. The estimate is a little bit off for each observation.\nThe difference between \\(y\\) (actual realization of the outcome) and \\(\\hat{y}\\) (our estimate using the regression model) is called the error term of the model and demonstrated with \\(e\\).\n\\[ y_i  =  \\hat{y}_i  + e_i   \\]\n\\[ y_i - \\hat{y}_i = e_i   \\]\n\\(e_i\\) is sometimes called residual. Residual and error are used interchangeably. Each error is visualised in Figure 7.3 below.\n\n\n\n\n\nFigure 7.3: Regression line\n\n\n\n\nCalculating each error term is straightforward.\n\n# calculate the error term\ndf$m1_error &lt;- df$InstPerform - df$m1_yhat \n\n# they are also stored in m1\n# error terms (residuals) of the regression:\nm1$residuals\n#&gt;           1           2           3           4           5           6 \n#&gt;  0.25045269  2.51964992 -1.77845215 -1.34575146  3.07745959 -0.35524110 \n#&gt;           7           8           9          10          11          12 \n#&gt; -0.08604386 -0.78794179 -1.35524110 -2.50429213  1.80329958  1.49570787 \n#&gt;          13          14          15          16          17          18 \n#&gt;  0.80329958 -2.03319697 -0.19670042  0.36110925 -1.92254041  3.49570787 \n#&gt;          19          20 \n#&gt; -1.22064248 -0.22064248"
  },
  {
    "objectID": "w07_regression.html#model-fit",
    "href": "w07_regression.html#model-fit",
    "title": "7  Bivariate Regression",
    "section": "7.9 Model Fit",
    "text": "7.9 Model Fit\nAs we discussed in the lecture, regression line is drawn by minimizing the sum of squared values of \\(e_i\\). We minimize \\(\\sum_{i=1}^{n}e_i^2\\) to estimate model coefficients. This approach is called ordinary least square (OLS) regression.\nWe can check how good the regression line fits the data. This is called goodness of fit. We have two measures of goodness of fit. - R squared (\\(R^2\\)) - Root Mean Squared Error (RMSE)\n\nscreenreg(m1, include.rmse = T)\n#&gt; \n#&gt; =========================\n#&gt;                 Model 1  \n#&gt; -------------------------\n#&gt; (Intercept)      2.71 ** \n#&gt;                 (0.84)   \n#&gt; CivicCommunity   0.57 ***\n#&gt;                 (0.07)   \n#&gt; -------------------------\n#&gt; R^2              0.81    \n#&gt; Adj. R^2         0.80    \n#&gt; Num. obs.       20       \n#&gt; RMSE             1.79    \n#&gt; =========================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n7.9.1 R Squared\n\\(R^2\\) shows how much variation in \\(Y\\) is explained by \\(X\\). \\(R^2\\) ranges between 0 and 1. In our regression, \\(R^2 = 0.81\\), which means 81% variation in \\(Y\\) is explained by \\(X\\). This value is equal to the square of \\(r\\) (correlation coefficient).\n\n# correlation coefficient squared:\ncor(df$InstPerform, df$CivicCommunity) ^ 2\n#&gt; [1] 0.8063829\n\nAdjusted \\(R^2\\) introduces a small correction to a measurement issue in \\(R^2\\). It introduces a penalty to \\(R^2\\) based on how many variables we have in the model. Adjusted \\(R^2\\) is lower than \\(R^2\\) because it is penalized. For our purposes, it is a technical detail and it does not really matter if you use \\(R^2\\) or Adjusted \\(R^2\\).\n\n\n7.9.2 RMSE\nRoot Mean Squared Error (a.k.a. residual standard error) shows how much \\(\\hat{y_i}\\) is different from \\(y_i\\). In texreg, we can include it by adding the option include.rmse = T. It is also possible to manually calculate it.\n\n# root mean squared residuals\nsqrt(sum(m1$residuals^2)/m1$df.residual)\n#&gt; [1] 1.789021"
  },
  {
    "objectID": "w08_regression.html#preliminaries",
    "href": "w08_regression.html#preliminaries",
    "title": "8  Multiple Regression",
    "section": "8.1 Preliminaries",
    "text": "8.1 Preliminaries\nLet’s start with clearing the environment, recalling libraries, and loading the data.\n\n# clear the environment\nrm(list = ls())\n\n# libraries\nlibrary(texreg)\nlibrary(tidyverse)"
  },
  {
    "objectID": "w08_regression.html#controlling-for-confounders",
    "href": "w08_regression.html#controlling-for-confounders",
    "title": "8  Multiple Regression",
    "section": "8.2 Controlling for Confounders",
    "text": "8.2 Controlling for Confounders\nIn the example below, we have only one independent variable (\\(X\\)).\n\\[ Y = \\alpha + \\beta * X + \\epsilon\\]\nMost often, the world is way more complex and investigating a direct relationship \\((X \\rightarrow Y)\\) is not appropriate because of confounders.\n\n\n\n\n\n\nConfounder Variable Z\n\n\n\n\n\n\n\n\ngraph LR\n    Z(\"Confounder (Z)\") --&gt; X(\"Explanatory Variable (X)\")\n    X(\"Explanatory Variable (X)\") --&gt; |?| Y(\"Outcome Variable (Y)\")\n    Z(\"Confounder (Z)\") --&gt; Y(\"Outcome Variable (Y)\")\n\n\nFigure 8.1: Z is confounding the relationship between X and Y\n\n\n\n\n\n\nTherefore, we need to control for \\(Z\\).\nWhat do we mean by controlling for \\(Z\\)? In the simplest sense, controlling for \\(Z\\) means investigating the relationship between \\(X\\) and \\(Y\\) for different values of \\(Z\\).\n\nLook at the \\(X\\)-\\(Y\\) relationship when \\(Z\\) = 0\nLook at the \\(X\\)-\\(Y\\) relationship when \\(Z\\) = 1\nLook at the \\(X\\)-\\(Y\\) relationship when \\(Z\\) = 2\nLook at the \\(X\\)-\\(Y\\) relationship when \\(Z\\) = 3\n…\n\nWe cannot really do this manually or one-by-one when \\(Z\\) is numerical or when we need to consider multiple confounding variables, both of which are often the case.\nWe incorporate \\(Z\\) directly into our regression model. This gives us the following regression model.\n\\[ Y = \\alpha + \\beta_1 * X + \\beta_2 * Z + \\epsilon\\]\n\n\n\n\n\n\nIncluding other variables\n\n\n\nWhen our primary goal is to predict \\(Y\\) rather than investigating the relationship between \\(X\\) and \\(Y\\), including other main predictors of \\(Y\\) will increase the ‘goodness of fit’ of the regression model. In this regard, we may want to include variables that are not directly related to \\(X\\), but is important for explaining \\(Y\\)\n\n\n\n\n\ngraph LR\n    %%X(\"Explanatory Variable (X)\") --&gt; Z(\"Confounder (Z)\")\n    Z(\"Confounder (Z)\") --&gt; X(\"Explanatory Variable (X)\")\n    X(\"Explanatory Variable (X)\") --&gt; Y(\"Outcome Variable (Y)\")\n    Z(\"Confounder (Z)\") --&gt; Y(\"Outcome Variable (Y)\")\n    A(\"Another Factor (K)\") --&gt; Y(\"Outcome Variable (Y)\")\n\n\nFigure 8.2: Considering K will improve the predictive power of the model\n\n\n\n\nThen, our model would be:\n\\[ Y = \\alpha + \\beta_1 * X + \\beta_2 * Z + \\beta_3 * K \\]\n\n\nPutting a new letter for each and every variable would be cumbersome and we would soon left out of letters. Therefore, we use subscripts to generalize the formula.\n\\[ Y = \\alpha + \\beta_1 * X_1 + \\beta_2 * X_2 + ... + \\beta_m * X_m + \\epsilon\\]\nIn the model above, we have \\(m\\) number of variables, giving us \\(\\beta\\) number of coefficients (one for each variable)."
  },
  {
    "objectID": "w08_regression.html#model-specification",
    "href": "w08_regression.html#model-specification",
    "title": "8  Multiple Regression",
    "section": "8.3 Model Specification",
    "text": "8.3 Model Specification\nYou might be asking the following question: which variables should I include in my model? There is no quick and easy answer to this question. The answer to this question comes from your theory and your objective. Recalling the lectures on theory, research design, and causality is important in this respect.\n\n\n\n\n\n\n\ngraph LR\n    X --&gt; Y\n    Z --&gt; Y\n    Z --&gt; X\n    K --&gt; Y\n    A --&gt; B\n    C --&gt; B\n\n\nFigure 8.3: Which variables to consider?\n\n\n\n\n\nImagine that your main goal is to explain the relationship between \\(X \\ \\rightarrow \\ Y\\), and your theory is summarized in Figure 8.3. In this case, we must consider \\(Z\\) because it is a possible confounder. If your main goal is to predict \\(Y\\), then it is a good idea to also include \\(K\\). In either case, however, there is no reason to include \\(A\\), \\(B\\), or \\(C\\).\nAgain in Figure 8.3, if your goal is to explain \\(B\\), then you should include \\(A\\) and \\(C\\) in your regression, and leave the others out.\nLet’s continue with another hypothetical example, which is summarized in Figure 8.4. This is your theory on voting behaviour and your main interest is to explain voting behaviour.\nAs we discussed in the lecture, there might be some people in the world voting the way they do because of their colour preference; such as voting Labour because they like red, or voting Conservative because they like blue. However, we do not expect colour choice to make a meaningful impact on vote choice: at best, a handful of people are making political decisions based on colour preferences. There are way more important factors, such as age, social class, wealth, education, etc. to explain voting behaviour. We would not consider favourite colour as a factor to include in a regression analysis to study voting behaviour.\nOn the other hand, favourite colour might be highly important in some areas of market research; for example, in explaining why people buy some products. A company may decide the colour of their products based on such research, where favourite colour is an important variable.\n\n\n\n\n\n\ngraph LR\n  A(Age)  --&gt; Y(\"Voting Behaviour\")\n  C(\"Social Class\") --&gt; Y(\"Voting Behaviour\")\n  C(\"Social Class\") --&gt; E(\"Education\")\n  E(\"Education\") --&gt; Y(\"Voting Behaviour\")\n  E(\"Education\") --&gt; W(\"Wealth\")\n  W(\"Wealth\") --&gt; E(\"Education\")\n  W(\"Wealth\") --&gt; Y(\"Voting Behaviour\")\n  C(\"Social Class\") --&gt; W(\"Wealth\")\n  S(\"Year Born\") --&gt; A2(\"Cohort\")\n  S(\"Year Born\") --&gt; A(\"Age\")\n  A2(\"Cohort\") --&gt; Y(\"Voting Behaviour\")\n  FC(\"Favourite Colour\") --&gt; |weak?/none?| Y(\"Voting Behaviour\")\n\n\nFigure 8.4: Explaining the relationship between age and voting behaviour"
  },
  {
    "objectID": "w08_regression.html#multivariate-regression-example-putnam-data-continued",
    "href": "w08_regression.html#multivariate-regression-example-putnam-data-continued",
    "title": "8  Multiple Regression",
    "section": "8.4 Multivariate Regression Example: Putnam Data Continued",
    "text": "8.4 Multivariate Regression Example: Putnam Data Continued\nLet’s load Putnam’s data again and continue our analysis.\n\n# Putmam Data\ndata &lt;- read.csv(\"data/putnam.csv\")\n\n# View(data)\nnames(data)\n#&gt; [1] \"Region\"         \"InstPerform\"    \"CivicCommunity\" \"NorthSouth\"    \n#&gt; [5] \"EconModern\"\n\n\n\n\n\n\n\nResearch Question\n\n\n\nWhy do some local governments in Italy perform better than others?\n\n\nConventional wisdom for answering this question was centred around economic development. To put it simply, more economically developed places create better political outcomes, including better functioning institutions. This way of thinking can be simplified as:\n\nEconomic development \\(\\Rightarrow\\) Institutional performance\n\nHowever, Putnam (1994) challenged this conventional thinking by proposing that civic culture and social capital are the driving force behind better institutional performance.\n\nCivic community \\(\\Rightarrow\\) Institutional performance\n\nLet’s analyse the data. Creating scatter plots is a nice place to start.\n\n\n\n\n\nIt looks like both \\(Civic\\ Community\\ Score\\) and \\(Economic\\ Modernization\\) are highly correlated with \\(Institutional Performance\\).\nLet’s run a series of regressions to further unpack the relationships.\n\n8.4.0.1 Model 1: Putnam’s Simple Argument\nOur first model is the one we run last week.\n\n# model 1:\nm1 &lt;- lm(InstPerform ~ CivicCommunity, data = data)\n\n\n\n8.4.0.2 Model 2: Conventional wisdom\n\n# model 1:\nm2 &lt;- lm(InstPerform ~ EconModern, data = data)\n\nLet’s see both regressions.\n\nscreenreg(list(m1, m2), include.rmse = T)\n#&gt; \n#&gt; ====================================\n#&gt;                 Model 1    Model 2  \n#&gt; ------------------------------------\n#&gt; (Intercept)      2.71 **    3.01 *  \n#&gt;                 (0.84)     (1.38)   \n#&gt; CivicCommunity   0.57 ***           \n#&gt;                 (0.07)              \n#&gt; EconModern                  0.59 ***\n#&gt;                            (0.12)   \n#&gt; ------------------------------------\n#&gt; R^2              0.81       0.57    \n#&gt; Adj. R^2         0.80       0.55    \n#&gt; Num. obs.       20         20       \n#&gt; RMSE             1.79       2.66    \n#&gt; ====================================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\nBoth variables, namely \\(Economic\\ Modernization\\) and \\(Civic\\ Community\\), are statistically significant and indicate a positive relationship with \\(Institutional\\ Performance\\) (see Models 1 and 2 above). The magnitude of the relationship is also similar for both variables:\n\nOne unit of increase in \\(Civic\\ Community\\) is associated with 0.57 unit increase in \\(Institutional\\ Performance\\) (see Model 1).\nOne unit of increase in \\(Economic\\ Modernization\\) is associated with 0.59 unit increase in \\(Institutional\\ Performance\\) (see Model 2).\n\nThis similarity in the magnitude of relationship (a.k.a. ‘effect size’) is also apparent in Figure 8.5.\n\n\n\n\n\nFigure 8.5: Regression Models 1 and 2\n\n\n\n\nWhat about model fit? Consider which model fit is better. Hint: we need to think about \\(R^2\\) and root mean squared error (RMSE).\n\n\n8.4.1 Controlling for North-South divide\nWe know that there are major differences in the North and the South of Italy. The regression we carried out do not consider this important dimension in any way. Let’s check the \\(NorthSouth\\) variable. It is a nominal level variable taking two values: North and South.\n\n# Frequency table for NorthSouth\ntable(data$NorthSouth, useNA = \"always\")\n#&gt; \n#&gt; North South  &lt;NA&gt; \n#&gt;    12     8     0\n\nLet’s recheck scatter plots while considering the North-South divide.\n\n# Institutional Performance and Civic Community\nggplot(data, aes(x = CivicCommunity, y = InstPerform, \n                 shape = NorthSouth,\n                 color = NorthSouth)) + \n  geom_point(size = 3) +\n  labs(x = \"Civic Community Score\", \n       y = \"Institutional Performance\", \n       shape = \"North-South\", \n       color = \"North-South\")\n\n\n\n\n\n# Institutional Performance and Economic Modernization\nggplot(data, aes(x = EconModern, y = InstPerform, \n                 shape = NorthSouth,\n                 color = NorthSouth)) + \n  geom_point(size = 3) +\n  labs(x = \"Economic Modernization\", \n       y = \"Institutional Performance\", \n       shape = \"North-South\", \n       color = \"North-South\")\n\n\n\n\nThings look slightly different now. Do these graphs give us any clue?\nNext, we are going to add \\(NorthSouth\\) to our regression models. But before, let’s think about how R handles categorical variables.\n\n\n\n\n\n\nCategorical Variables in R\n\n\n\nTo make reading the table easier, we are going to tell R that \\(NorthSouth\\) is a categorical variable. Otherwise, it will make an educated guess. It would work, but it would be harder to understand for the reader. For categorical variables, we need to allocate one category as the baseline (a.k.a benchmark category).\n\n# check the data$NorthSouth\nhead(data$NorthSouth, 5)\n#&gt; [1] \"South\" \"South\" \"South\" \"South\" \"North\"\n\n# Tell R that North-South is a categorical variable with two nominal groups\ndata$NorthSouth &lt;- factor(data$NorthSouth, levels = c(\"North\", \"South\"))\n\n# Let's see again:\nhead(data$NorthSouth, 5)\n#&gt; [1] South South South South North\n#&gt; Levels: North South\n# R now considers it as categorical\n# The first 'level' is the categorical variable. It is North in this case\n\n# Change the reference category to South\ndata$NorthSouth &lt;- relevel(data$NorthSouth, ref = \"South\")\n\n# Let's see again:\nhead(data$NorthSouth, 5)\n#&gt; [1] South South South South North\n#&gt; Levels: South North\n\nNow, the reference category is South in \\(NorthSouth\\). Let’s change it back to North.\n\n# Change the reference category to North\ndata$NorthSouth &lt;- relevel(data$NorthSouth, ref = \"North\")\n\n# Let's see again:\nhead(data$NorthSouth, 3)\n#&gt; [1] South South South\n#&gt; Levels: North South\n\n\n\nWe are almost ready to run the regressions. Note that the variable \\(NorthSouth\\) is a nominal variable with two categories (i.e., North and South) and the baseline for is North. Once we define this, what R does behind the curtains is that it treats this variable as binary where zero refers to North (the baseline) and 1 refers to South.\nSo when moving from Model 1 to Model 1b (with control), our regression equation becomes as follows:\n\\[Model\\ 1b:\\ \\ \\ \\  Y = \\alpha + \\beta_1 * CivicCommunity + \\beta_2 * South +  \\epsilon\\] \\(South\\) is a binary variable. When an observation is from the North, Model 1b becomes the following:\n\\[When\\ South = 0 \\ \\ \\rightarrow\\ \\  Y = \\alpha + \\beta_1 * CivicCommunity + \\beta_2 * 0 +  \\epsilon \\] Model 1b for observations from the South:\n\\[When\\ South = 0 \\ \\ \\rightarrow\\ \\ Y = \\alpha + \\beta_1 * CivicCommunity + \\epsilon\\]\nModel 1b becomes the following for observations from the South:\n\\[When\\ South = 1 \\ \\ \\rightarrow\\ \\  Y = \\alpha + \\beta_1 * CivicCommunity + \\beta_2 * 1 +  \\epsilon \\] Putting the \\(\\beta_2\\) to front:\n\\[When\\ South = 1 \\ \\ \\rightarrow\\ \\  Y = \\beta_2 + \\alpha + \\beta_1 * CivicCommunity +  \\epsilon\\]\nIn other words, the binary variable \\(NorthSouth\\) will allow the intercept to vary by North-South. Let’s run the model in R.\n\n# Model 1b: Putnam's argument while controlling for the North-South divide\nm1b &lt;- lm(InstPerform ~ CivicCommunity + NorthSouth , data = data)\n\nSimilarly, we introduce \\(NorthSouth\\) when wo move from Model 2 to Model 2b:\n\\[Model\\ 2b:\\ \\ \\ \\  Y = \\alpha + \\beta_1 * EconModern + \\beta_2 * South +  \\epsilon\\]\n\n# Model 2b: Conventional wisdom while controlling for the North-South divide\nm2b &lt;- lm(InstPerform ~ EconModern + NorthSouth, data = data)\n\nNow, we are ready to see all the results and compare them.\n\n# results\nscreenreg(list(m1, m1b, m2, m2b), \n          include.rmse = T, \n          custom.model.names =c(\"Model 1\", \"Model 1b\", \"Model 2\", \"Model 2b\"))\n#&gt; \n#&gt; =========================================================\n#&gt;                  Model 1    Model 1b  Model 2    Model 2b\n#&gt; ---------------------------------------------------------\n#&gt; (Intercept)       2.71 **    2.65      3.01 *    12.11 **\n#&gt;                  (0.84)     (3.50)    (1.38)     (3.16)  \n#&gt; CivicCommunity    0.57 ***   0.57 *                      \n#&gt;                  (0.07)     (0.21)                       \n#&gt; NorthSouthSouth              0.05                -6.88 **\n#&gt;                             (2.68)               (2.23)  \n#&gt; EconModern                             0.59 ***  -0.02   \n#&gt;                                       (0.12)     (0.22)  \n#&gt; ---------------------------------------------------------\n#&gt; R^2               0.81       0.81      0.57       0.73   \n#&gt; Adj. R^2          0.80       0.78      0.55       0.69   \n#&gt; Num. obs.        20         20        20         20      \n#&gt; RMSE              1.79       1.84      2.66       2.19   \n#&gt; =========================================================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\nWhile moving from Model 1 to Model 1b, we introduced a control for North-South divide. Even after controlling for \\(NorthSouth\\), \\(CivicCommunity\\) is still statistically significant. One unit of increase in \\(CivicCommunity\\) is associated with 0.57 units \\(InstPerform\\).\nHowever, after controlling for \\(NorthSouth\\), the relationship between \\(EconModern\\) and \\(InstPerform\\) disappeared. The coefficient for \\(EconModern\\) is -0.02 and this coefficient is not statistically different than zero (i.e., no effect).\nThis aspect becomes clearer when we add regression lines.\n\n# Institutional Performance and Civic Community\nggplot(data, aes(x = CivicCommunity, y = InstPerform, \n                 shape = NorthSouth,\n                 color = NorthSouth)) + \n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\") + \n  labs(x = \"Civic Community Score\", \n       y = \"Institutional Performance\", \n       shape = \"North-South\", \n       color = \"North-South\")\n\n\n\n\n\n# Institutional Performance and Economic Modernization\nggplot(data, aes(x = EconModern, y = InstPerform, \n                 shape = NorthSouth,\n                 color = NorthSouth)) + \n  geom_point(size = 2) +\n  geom_smooth(method = \"lm\") + \n  labs(x = \"Economic Modernization\", \n       y = \"Institutional Performance\", \n       shape = \"North-South\", \n       color = \"North-South\")\n\n\n\n\n\n\n8.4.2 Marginal Effects\nLet’s zoom in on the effects of variables we estimated using different modelling strategies. Recall that model coefficients directly indicate the magnitude of association.\n\nscreenreg(list(m2, m2b), include.rmse = T, \n          custom.model.names = c(\"Model 2\", \"Model 2b\"))\n#&gt; \n#&gt; ====================================\n#&gt;                  Model 2    Model 2b\n#&gt; ------------------------------------\n#&gt; (Intercept)       3.01 *    12.11 **\n#&gt;                  (1.38)     (3.16)  \n#&gt; EconModern        0.59 ***  -0.02   \n#&gt;                  (0.12)     (0.22)  \n#&gt; NorthSouthSouth             -6.88 **\n#&gt;                             (2.23)  \n#&gt; ------------------------------------\n#&gt; R^2               0.57       0.73   \n#&gt; Adj. R^2          0.55       0.69   \n#&gt; Num. obs.        20         20      \n#&gt; RMSE              2.66       2.19   \n#&gt; ====================================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\n\n8.4.2.1 Model 2\nStarting with the conventional wisdom (Model 2 and Model 2b), the coefficient for \\(EconModern\\) is 0.59 and -0.02 respectively. This means that the effect we see in Model 2 disappears once we control for the North-South.\nWe can visualize these using the effects() function. First, make sure to install it by typing install.packages(\"effects\").\n\nlibrary(effects)\n#&gt; Loading required package: carData\n#&gt; lattice theme set by effectsTheme()\n#&gt; See ?effectsTheme for details.\n\n# marginal effects of EconModern in Model 2\nm2_econ &lt;- effect(term = \"EconModern\", mod = m2)\n\nThe marginal effect of \\(EconModern\\) in Model 2 (which is stored in m2_econ) is shown below.\n\n# see the object strong marginal effect of EconModern in Model 2\nm2_econ\n#&gt; \n#&gt;  EconModern effect\n#&gt; EconModern\n#&gt;       2.5       6.6        11        15        19 \n#&gt;  4.483062  6.897503  9.488611 11.844163 14.199715\n\nThis means that:\n\nWhen X = 2.5, expected Y is: 4.483062\nWhen X = 6.6, expected Y is: 6.897503\nWhen X = 11, expected Y is: 9.488611\nWhen X = 15, expected Y is: 11.844163\nWhen X = 19, expected Y is: 14.199715\n\n\n# let's plot it\nplot(m2_econ)\n\n\n\n\nThe plot above visualizes \\(\\beta_1 = 0.59\\) in Model 2. However, it is missing proper titles and considering that we have many models, it might be easy to mix one plot with another. Therefore it is imperative to add proper titles. We can also define he scale of x and y axes.\n\n# Marginal Effects of EconModern in Model 2\nplot(m2_econ,\n     main  = \"Model 2: Economic Modernization Only\",\n     ylab = \"Institutional Performance\",\n     xlab = \"Economic Modernization\",\n     ylim = c(0, 20), \n     xlim = c(0, 18) \n     )\n\n\n\n\nFigure 8.6: Expected Institutional Performance with different values of Economic Modernization\n\n\n\n\n\n\n8.4.2.2 Marginal effects in Model 2b\nNext, let’s turn our attention to Model 2b, which introduces the North-South control. Here, we need to estimate two scenarios: (1) the region is located in the North. (2) the region is located in the South. Recall that controlling for the North-South means adopting such an approach. In a way, Model 2b has two equations:\n\\(When\\ South = 0 \\ \\ \\rightarrow\\ \\ Y = \\alpha + \\beta_1 * CivicCommunity + \\epsilon\\) \\(When\\ South = 1 \\ \\ \\rightarrow\\ \\ Y = \\alpha + \\beta_2 + \\beta_1 * CivicCommunity + \\epsilon\\)\nUsing the input data, R prepares a new matrix suitable for mathematical analysis used in regression. We can check this matrix by relying on the model.matrix().\n\nmodel.matrix(m2b)\n#&gt;    (Intercept) EconModern NorthSouthSouth\n#&gt; 1            1        7.0               1\n#&gt; 2            1        3.0               1\n#&gt; 3            1        3.0               1\n#&gt; 4            1        6.5               1\n#&gt; 5            1       13.0               0\n#&gt; 6            1       14.5               0\n#&gt; 7            1       12.5               0\n#&gt; 8            1       15.5               0\n#&gt; 9            1       19.0               0\n#&gt; 10           1       10.5               0\n#&gt; 11           1        2.5               1\n#&gt; 12           1       17.0               0\n#&gt; 13           1        4.0               1\n#&gt; 14           1        8.5               1\n#&gt; 15           1        5.5               1\n#&gt; 16           1       14.5               0\n#&gt; 17           1       12.5               0\n#&gt; 18           1       11.0               0\n#&gt; 19           1       15.0               0\n#&gt; 20           1       13.5               0\n#&gt; attr(,\"assign\")\n#&gt; [1] 0 1 2\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$NorthSouth\n#&gt; [1] \"contr.treatment\"\n\nNote that a new variable called \\(NorthSouthSouth\\) was created by R. This is a binary variable taking the values 1 when the observation is from the South and 0 otherwise (when the observation is from the North).\nWe are going to estimate the Institutional Performance based on different values of Economic Modernization for North and South.\n\n# Marginal Effects\n# South:\nm2b_econ_s1 &lt;- effect(term = \"EconModern\",\n                      mod = m2b,\n                      given.values = c(\"NorthSouthSouth\" = 1)\n                      )\n\n# see the effects:\nm2b_econ_s1\n#&gt; \n#&gt;  EconModern effect\n#&gt; EconModern\n#&gt;      2.5      6.6       11       15       19 \n#&gt; 5.173533 5.093939 5.008520 4.930866 4.853213\n\nThis output tells me the following.\nWhen the region is in the South and … :\n\nEconomic Modernization = 2.5 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 5.17\\)\nEconomic Modernization = 6.6 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 5.09\\)\nEconomic Modernization = 11 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 5.01\\)\nEconomic Modernization = 15 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 4.93\\)\nEconomic Modernization = 19 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 4.85\\)\n\nLet’s plot these.\n\n# Marginal Effects of EconModern in Model 2b (South)\nplot(m2b_econ_s1,\n     main  = \"Model 2b: Economic Modernization (South Italy)\",\n     ylab = \"Institutional Performance\",\n     xlab = \"Economic Modernization\",\n     ylim = c(0, 19), \n     xlim = c(0, 18) \n     )\n\n\n\n\n\n# North:\nm2b_econ_s0 &lt;- effect(term = \"EconModern\",\n                      mod = m2b,\n                      given.values = c(\"NorthSouthSouth\" = 0)\n                      )\n\n# see the effects:\nm2b_econ_s0\n#&gt; \n#&gt;  EconModern effect\n#&gt; EconModern\n#&gt;      2.5      6.6       11       15       19 \n#&gt; 12.05740 11.97780 11.89238 11.81473 11.73708\n\nThis output tells me the following.\nWhen the region is in the North and … :\n\nEconomic Modernization = 2.5 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 12.06\\)\nEconomic Modernization = 6.6 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 11.98\\)\nEconomic Modernization = 11 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 11.89\\)\nEconomic Modernization = 15 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 11.82\\)\nEconomic Modernization = 19 \\(\\ \\ \\ \\rightarrow \\ \\ \\ \\hat{Y} = 11.34\\)\n\nLet’s also plot these.\n\n# Marginal Effects of EconModern in Model 2b (North)\nplot(m2b_econ_s0,\n     main  = \"Model 2b: Economic Modernization (North Italy)\",\n     ylab = \"Institutional Performance\",\n     xlab = \"Economic Modernization\",\n     ylim = c(0, 19), \n     xlim = c(0, 18) \n     )\n\n\n\n\nIt is possible to put these last two figures next to each other by using the package gridExtra. As usual, please install it first by running install.packages().\n\nlibrary(\"gridExtra\")\n\n\n# Marginal Effects of EconModern in North\n# plot saved in an object\np2b_1 &lt;- plot(m2b_econ_s0,\n           main  = \"North Italy\",\n           ylab = \"Institutional Performance\",\n           xlab = \"Economic Modernization\",\n           ylim = c(0, 19), \n           xlim = c(0, 18) \n           )\n\n\n# Marginal Effects of EconModern in South\n# plot saved in an object\np2b_2 &lt;- plot(m2b_econ_s1,\n           main  = \"South Italy\",\n           ylab = \"Institutional Performance\",\n           xlab = \"Economic Modernization\",\n           ylim = c(0, 19), \n           xlim = c(0, 18) \n           )\n\n\n# Put two plots next to each other:\ngrid.arrange(p2b_1, p2b_2, ncol = 2)\n\n\n\n\nFigure 8.7: The relationship between Institutional Performance and Economic Modernization after Controlling for North-South\n\n\n\n\nIt is clear that Economic Modernization does not have a relationship with \\(Institutional Performance\\) once we control for the North-South difference.\n\n\n8.4.2.3 Marginal effects in Model 1b\nWhat about Putnam’s claim? Let’s reproduce the steps we did for Model 2b for Model 1b.\n\n# See the model matrix\nmodel.matrix(m1b)\n#&gt;    (Intercept) CivicCommunity NorthSouthSouth\n#&gt; 1            1            8.0               1\n#&gt; 2            1            4.0               1\n#&gt; 3            1            1.0               1\n#&gt; 4            1            2.0               1\n#&gt; 5            1           18.0               0\n#&gt; 6            1           17.0               0\n#&gt; 7            1           13.0               0\n#&gt; 8            1           16.0               0\n#&gt; 9            1           17.0               0\n#&gt; 10           1           15.5               0\n#&gt; 11           1            3.5               1\n#&gt; 12           1           15.5               0\n#&gt; 13           1            3.5               1\n#&gt; 14           1            8.5               1\n#&gt; 15           1            3.5               1\n#&gt; 16           1           17.5               0\n#&gt; 17           1           18.0               0\n#&gt; 18           1           15.5               0\n#&gt; 19           1           15.0               0\n#&gt; 20           1           15.0               0\n#&gt; attr(,\"assign\")\n#&gt; [1] 0 1 2\n#&gt; attr(,\"contrasts\")\n#&gt; attr(,\"contrasts\")$NorthSouth\n#&gt; [1] \"contr.treatment\"\n\nCalculate the marginal effects.\n\n# Marginal effects for North\n\n# North:\nm1b_civic_s0 &lt;- effect(term = \"CivicCommunity\",\n                      mod = m1b,\n                      given.values = c(\"NorthSouthSouth\" = 0)\n                      )\n\n# South:\nm1b_civic_s1 &lt;- effect(term = \"CivicCommunity\",\n                      mod = m1b,\n                      given.values = c(\"NorthSouthSouth\" = 1)\n                      )\n\nNext, plotting.\n\nplot(m1b_civic_s0,\n     main = \"Model 1b (North)\",\n     xlab = \"Civic Community\",\n     ylab = \"Institutional Performance\")\n\n\n\n\nplot(m1b_civic_s1,\n     main = \"Model 1b (South)\",\n     xlab = \"Civic Community\",\n     ylab = \"Institutional Performance\")\n\n\n\n\nLet’s put these last two graphs together.\n\n# Marginal Effects of CivicCommunity in North\n# plot saved in an object\np1b_1 &lt;- plot(m1b_civic_s0,\n              main = \"North of Italy\",\n              xlab = \"Civic Community\",\n              ylab = \"Institutional Performance\",\n              ylim = c(0,19),\n              xlim = c(0,16)\n              )\n# Marginal Effects of CivicCommunity in South\n# plot saved in an object\np1b_2 &lt;- plot(m1b_civic_s1,\n              main = \"South of Italy\",\n              xlab = \"Civic Community\",\n              ylab = \"Institutional Performance\",\n              ylim = c(0,19),\n              xlim = c(0,16)\n              )\n\n# Put two plots next to each other:\ngrid.arrange(p1b_1, p1b_2, ncol = 2)\n\n\n\n\nFigure 8.8: The relationship between Institutional Performance and Civic Community after Controlling for North-South\n\n\n\n\n\n\n\n8.4.3 Model 3: Controlling for North-South and Economic Modernization\nFinally, we can have a model where we add all three independent variables.\n\\[Model\\ 3: Y = \\alpha + \\beta_1 * CivicCommunity + \\beta_2 *EconModern  + \\beta_3 * South +  \\epsilon\\]\n\n# Model 3 regression\nm3 &lt;- lm(InstPerform ~ CivicCommunity + EconModern + NorthSouth, data = data)\n\n# results\nscreenreg(list(m1, m1b, m2, m2b, m3), \n          include.rmse = T, \n          custom.model.names =c(\"Model 1\", \"Model 1b\", \n                                \"Model 2\", \"Model 2b\", \"Model 3\"))\n#&gt; \n#&gt; ===================================================================\n#&gt;                  Model 1    Model 1b  Model 2    Model 2b  Model 3 \n#&gt; -------------------------------------------------------------------\n#&gt; (Intercept)       2.71 **    2.65      3.01 *    12.11 **   4.35   \n#&gt;                  (0.84)     (3.50)    (1.38)     (3.16)    (3.64)  \n#&gt; CivicCommunity    0.57 ***   0.57 *                         0.70 **\n#&gt;                  (0.07)     (0.21)                         (0.23)  \n#&gt; NorthSouthSouth              0.05                -6.88 **  -0.86   \n#&gt;                             (2.68)               (2.23)    (2.70)  \n#&gt; EconModern                             0.59 ***  -0.02     -0.27   \n#&gt;                                       (0.12)     (0.22)    (0.20)  \n#&gt; -------------------------------------------------------------------\n#&gt; R^2               0.81       0.81      0.57       0.73      0.83   \n#&gt; Adj. R^2          0.80       0.78      0.55       0.69      0.79   \n#&gt; Num. obs.        20         20        20         20        20      \n#&gt; RMSE              1.79       1.84      2.66       2.19      1.80   \n#&gt; ===================================================================\n#&gt; *** p &lt; 0.001; ** p &lt; 0.01; * p &lt; 0.05\n\nIn Model 3, only \\(CivicCommunity\\) has a significant effect on \\(InstPerform\\). How to demonstrate marginal effects of a variables of interest when we have multiple control variables?\nR will give us an output if we ask for the effect of \\(CivicCommunity\\) and left the other variables unspecified.\n\neffect(term = \"CivicCommunity\", mod = m3)\n#&gt; \n#&gt;  CivicCommunity effect\n#&gt; CivicCommunity\n#&gt;         1       5.2       9.5        14        18 \n#&gt;  1.905409  4.845243  7.855073 11.004895 13.804737\n\nWhat happening behind the curtains is that R plugs in the mean values in the data. Taking the mean of categorical variables are not really meaningful. Can we really have a region of 0.5 North? Not really.\nLet’s define each bit one by one. I am going to tell R to calculate expected values of Institutional Performance with respect to different values of Civic Community for North and South separately. And for Economic Modernization, I am going to plug in the mean value of the respective geography.\n\n\n\n\n\n\nWarning\n\n\n\nUsing the model matrix instead of the original data is advised at this stage because of possible missingness (see the call-out box below) but we would like to keep things simple while learning. We do not have any missingness in Putnam’s data anyway.\n\n\nWe are going to calculate the mean of Economic Modernization for South and North separetely.\n\n# Mean of Economic Modernization in the South\nem_mean_south &lt;- data$EconModern[data$NorthSouth == \"South\"] |&gt; mean()\n\n# Mean of Economic Modernization in the North\nem_mean_north &lt;- data$EconModern[data$NorthSouth == \"North\"] |&gt; mean()\n\nIt is time to use the effect() function.\n\n# For South\nm3_civic_s0 &lt;- effect(term = \"CivicCommunity\", \n                      mod = m3,\n                      given.values = c(\"NorthSouthSouth\" = 1,\n                                       \"EconModern\" = em_mean_south)\n                      )\n\n# For North\nm3_civic_s1 &lt;- effect(term = \"CivicCommunity\", \n                      mod = m3,\n                      given.values = c(\"NorthSouthSouth\" = 0,\n                                       \"EconModern\" = em_mean_north)\n                      )\n\nLet’s see the expected values of Institutional Performance with respect to different values of Civic Community in the North and the South when we plug in the mean Economic Modernization for the respective geographies.\n\n# Predictions for Institutional Performance in the North\nm3_civic_s0\n#&gt; \n#&gt;  CivicCommunity effect\n#&gt; CivicCommunity\n#&gt;         1       5.2       9.5        14        18 \n#&gt;  2.850128  5.789962  8.799792 11.949615 14.749457\n\nThis means that a Northern Region with an average economic modernization typical in the North:\n\nWhen Civic Community = 1, expected Y is: 2.850128\nWhen Civic Community = 5.2, expected Y is: 5.789962\nWhen Civic Community = 9.5, expected Y is: 8.799792\nWhen Civic Community = 14, expected Y is: 11.949615\nWhen Civic Community = 18, expected Y is: 14.749457\n\n\n# Predictions for Institutional Performance in the South\nm3_civic_s1\n#&gt; \n#&gt;  CivicCommunity effect\n#&gt; CivicCommunity\n#&gt;         1       5.2       9.5        14        18 \n#&gt;  1.275596  4.215430  7.225260 10.375082 13.174924\n\nThese are expected Institutional Performance of a Southern Region with an average economic modernization typical in the South.\nFinally, let’s plot them.\n\n# Marginal Effects of CivicCommunity in North\n# plot saved in an object\np3_1 &lt;-  plot(m3_civic_s0,\n              main = \"North of Italy\",\n              xlab = \"Civic Community\",\n              ylab = \"Institutional Performance\",\n              ylim = c(0,19),\n              xlim = c(0,16)\n              )\n\n# Marginal Effects of CivicCommunity in South\n# plot saved in an object\np3_2 &lt;- plot(m3_civic_s1,\n              main = \"South of Italy\",\n              xlab = \"Civic Community\",\n              ylab = \"Institutional Performance\",\n              ylim = c(0,19),\n              xlim = c(0,16)\n              )\n\n# put these together\ngrid.arrange(p3_1, p3_2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\neffects() when other variables left undspecified\n\n\n\n\n\nWe mentioned that when using the effects() function, if you leave the other variables in the model undefined, R automatically plugs in the mean of that variable in the model matrix.\nHow do we know this? Well, we could check it.\n\n# Get the names of the variables in the model matrix of Model 3\n\n# check the names of variables in the model matrix for m3:\nmodel.matrix(m3) |&gt; colnames()\n#&gt; [1] \"(Intercept)\"     \"CivicCommunity\"  \"EconModern\"      \"NorthSouthSouth\"\n\n# our main X is Civic Community. \n# our main EconModern is the first control. I call this X2\nx2 &lt;- model.matrix(m3)[,\"EconModern\"]\n\n# take its mean\nx2.mean &lt;- mean(x2)\n\n# second control variable is NorthSouthSouth. lets call it x3\nx3 &lt;- model.matrix(m3)[,\"NorthSouthSouth\"]\n\n# mean of x3\nx3.mean &lt;- mean(x3)\n\n# see the effect when keeping all their mean values\neffect(term = \"CivicCommunity\", \n       mod = m3, \n       given.values = c(\"EconModern\" = x2.mean,\n                        \"NorthSouthSouth\" = x3.mean)\n       )\n#&gt; \n#&gt;  CivicCommunity effect\n#&gt; CivicCommunity\n#&gt;         1       5.2       9.5        14        18 \n#&gt;  1.905409  4.845243  7.855073 11.004895 13.804737\n\n# see the effect when left. undefinex\neffect(term = \"CivicCommunity\", \n       mod = m3)\n#&gt; \n#&gt;  CivicCommunity effect\n#&gt; CivicCommunity\n#&gt;         1       5.2       9.5        14        18 \n#&gt;  1.905409  4.845243  7.855073 11.004895 13.804737\n\n# are they equal to each other?\n# yes they are"
  },
  {
    "objectID": "resources.html#introduction-to-modern-statistics",
    "href": "resources.html#introduction-to-modern-statistics",
    "title": "Resources",
    "section": "Introduction to Modern Statistics",
    "text": "Introduction to Modern Statistics\n\n\n\n\n\n\n\n\n\nIntroduction to Modern Statistics by Mine Çetinkaya-Rundel and Johanna Hardin is an excellent textbook for learning foundational concepts in statistics and data analysis.\nThe online textbook is free and available at https://openintro-ims.netlify.app/.\nAlso see http://openintro.org/book/ims for supplementary materials and additional resources."
  },
  {
    "objectID": "resources.html#hand-on-programming-with-r",
    "href": "resources.html#hand-on-programming-with-r",
    "title": "Resources",
    "section": "Hand-On Programming with R:",
    "text": "Hand-On Programming with R:\n\n\nHand-On Programming with R by Garrett Grolemund is a straightforward introduction to R. It is useful to learn the basics of R notation.\nWe cover most of the content in Part 1 & 2 in the first four weeks, but if you want to approach the same content from a different angle, you will find this textbook useful.\nIt is freely available here: https://rstudio-education.github.io/hopr/"
  },
  {
    "objectID": "resources.html#r-for-data-science",
    "href": "resources.html#r-for-data-science",
    "title": "Resources",
    "section": "R for Data Science",
    "text": "R for Data Science\n\n\n\n\n\n\n\n\n\nR for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund is an introductory textbook on getting started with R and tidyverse for data management, analysis and visualisation. It is an excellent source to learn the basics of R, R Studio and tidyverse.\nIt can be used as a reference textbook, especially when you are struggling to recall the syntax. It has many examples to get a grasp (or remember) how to use many base R and tidyverse functions.\nIt is free and available here: https://r4ds.hadley.nz/"
  },
  {
    "objectID": "resources.html#statistical-inference-via-data-science",
    "href": "resources.html#statistical-inference-via-data-science",
    "title": "Resources",
    "section": "Statistical Inference via Data Science:",
    "text": "Statistical Inference via Data Science:\n\n\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse by Chester Ismay and Albert Y. Kim is another excellent source for learning statistics and data science with R.\nThe coverage of this textbook fits well with our module. You can only rely on this textbook to revise the content we covered.\nIt is free and available at https://moderndive.com/."
  },
  {
    "objectID": "resources.html#r-graphics-cookbook",
    "href": "resources.html#r-graphics-cookbook",
    "title": "Resources",
    "section": "R Graphics Cookbook",
    "text": "R Graphics Cookbook\n\n\n\n\n\n\n\n\n\nR Graphics Cookbook by Winston Chang is a detailed textbook on creating visualisations in R via using ggplot2.\nIt is free and available here: https://r-graphics.org/"
  },
  {
    "objectID": "resources.html#ggplot2-elegant-graphics-for-data-analysis",
    "href": "resources.html#ggplot2-elegant-graphics-for-data-analysis",
    "title": "Resources",
    "section": "ggplot2: Elegant Graphics for Data Analysis",
    "text": "ggplot2: Elegant Graphics for Data Analysis\n\n\nThis book explains the underlying theory behind ggplot2.\nIt is available here: https://ggplot2-book.org/"
  }
]